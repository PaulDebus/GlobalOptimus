#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass Definitions/mdpi
\begin_preamble
%  LaTeX support: latex@mdpi.com 
%  For support, please attach all files needed for compiling as well as the log file, and specify your operating system, LaTeX version, and LaTeX editor.

%=================================================================


% For posting an early version of this manuscript as a preprint, you may use "preprints" as the journal and change "submit" to "accept". The document class line would be, e.g., \documentclass[preprints,article,accept,moreauthors,pdftex]{mdpi}. This is especially recommended for submission to arXiv, where line numbers should be removed before posting. For preprints.org, the editorial staff will make this change immediately prior to posting.

%--------------------
% Class Options:
%--------------------
%----------
% journal
%----------
% Choose between the following MDPI journals:
% acoustics, actuators, addictions, admsci, adolescents, aerospace, agriculture, agriengineering, agronomy, ai, algorithms, allergies, alloys, analytica, animals, antibiotics, antibodies, antioxidants, applbiosci, appliedchem, appliedmath, applmech, applmicrobiol, applnano, applsci, aquacj, architecture, arts, asc, asi, astronomy, atmosphere, atoms, audiolres, automation, axioms, bacteria, batteries, bdcc, behavsci, beverages, biochem, bioengineering, biologics, biology, biomass, biomechanics, biomed, biomedicines, biomedinformatics, biomimetics, biomolecules, biophysica, biosensors, biotech, birds, bloods, blsf, brainsci, breath, buildings, businesses, cancers, carbon, cardiogenetics, catalysts, cells, ceramics, challenges, chemengineering, chemistry, chemosensors, chemproc, children, chips, cimb, civileng, cleantechnol, climate, clinpract, clockssleep, cmd, coasts, coatings, colloids, colorants, commodities, compounds, computation, computers, condensedmatter, conservation, constrmater, cosmetics, covid, crops, cryptography, crystals, csmf, ctn, curroncol, currophthalmol, cyber, dairy, data, dentistry, dermato, dermatopathology, designs, diabetology, diagnostics, dietetics, digital, disabilities, diseases, diversity, dna, drones, dynamics, earth, ebj, ecologies, econometrics, economies, education, ejihpe, electricity, electrochem, electronicmat, electronics, encyclopedia, endocrines, energies, eng, engproc, ent, entomology, entropy, environments, environsciproc, epidemiologia, epigenomes, est, fermentation, fibers, fintech, fire, fishes, fluids, foods, forecasting, forensicsci, forests, foundations, fractalfract, fuels, futureinternet, futureparasites, futurepharmacol, futurephys, futuretransp, galaxies, games, gases, gastroent, gastrointestdisord, gels, genealogy, genes, geographies, geohazards, geomatics, geosciences, geotechnics, geriatrics, hazardousmatters, healthcare, hearts, hemato, heritage, highthroughput, histories, horticulturae, humanities, humans, hydrobiology, hydrogen, hydrology, hygiene, idr, ijerph, ijfs, ijgi, ijms, ijns, ijtm, ijtpp, immuno, informatics, information, infrastructures, inorganics, insects, instruments, inventions, iot, j, jal, jcdd, jcm, jcp, jcs, jdb, jeta, jfb, jfmk, jimaging, jintelligence, jlpea, jmmp, jmp, jmse, jne, jnt, jof, joitmc, jor, journalmedia, jox, jpm, jrfm, jsan, jtaer, jzbg, kidney, kidneydial, knowledge, land, languages, laws, life, liquids, literature, livers, logics, logistics, lubricants, lymphatics, machines, macromol, magnetism, magnetochemistry, make, marinedrugs, materials, materproc, mathematics, mca, measurements, medicina, medicines, medsci, membranes, merits, metabolites, metals, meteorology, methane, metrology, micro, microarrays, microbiolres, micromachines, microorganisms, microplastics, minerals, mining, modelling, molbank, molecules, mps, msf, mti, muscles, nanoenergyadv, nanomanufacturing, nanomaterials, ncrna, network, neuroglia, neurolint, neurosci, nitrogen, notspecified, nri, nursrep, nutraceuticals, nutrients, obesities, oceans, ohbm, onco, oncopathology, optics, oral, organics, organoids, osteology, oxygen, parasites, parasitologia, particles, pathogens, pathophysiology, pediatrrep, pharmaceuticals, pharmaceutics, pharmacoepidemiology, pharmacy, philosophies, photochem, photonics, phycology, physchem, physics, physiologia, plants, plasma, pollutants, polymers, polysaccharides, poultry, powders, preprints, proceedings, processes, prosthesis, proteomes, psf, psych, psychiatryint, psychoactives, publications, quantumrep, quaternary, qubs, radiation, reactions, recycling, regeneration, religions, remotesensing, reports, reprodmed, resources, rheumato, risks, robotics, ruminants, safety, sci, scipharm, seeds, sensors, separations, sexes, signals, sinusitis, skins, smartcities, sna, societies, socsci, software, soilsystems, solar, solids, sports, standards, stats, stresses, surfaces, surgeries, suschem, sustainability, symmetry, synbio, systems, taxonomy, technologies, telecom, test, textiles, thalassrep, thermo, tomography, tourismhosp, toxics, toxins, transplantology, transportation, traumacare, traumas, tropicalmed, universe, urbansci, uro, vaccines, vehicles, venereology, vetsci, vibration, viruses, vision, waste, water, wem, wevj, wind, women, world, youth, zoonoticdis 

%---------
% article
%---------
% The default type of manuscript is "article", but can be replaced by: 
% abstract, addendum, article, book, bookreview, briefreport, casereport, comment, commentary, communication, conferenceproceedings, correction, conferencereport, entry, expressionofconcern, extendedabstract, datadescriptor, editorial, essay, erratum, hypothesis, interestingimage, obituary, opinion, projectreport, reply, retraction, review, perspective, protocol, shortnote, studyprotocol, systematicreview, supfile, technicalnote, viewpoint, guidelines, registeredreport, tutorial
% supfile = supplementary materials

%----------
% submit
%----------
% The class option "submit" will be changed to "accept" by the Editorial Office when the paper is accepted. This will only make changes to the frontpage (e.g., the logo of the journal will get visible), the headings, and the copyright information. Also, line numbering will be removed. Journal info and pagination for accepted papers will also be assigned by the Editorial Office.

%------------------
% moreauthors
%------------------
% If there is only one author the class option oneauthor should be used. Otherwise use the class option moreauthors.

%---------
% pdftex
%---------
% The option pdftex is for use with pdfLaTeX. If eps figures are used, remove the option pdftex and use LaTeX and dvi2pdf.

%=================================================================
% MDPI internal commands - do not modify
\firstpage{1} 
 
\setcounter{page}{\@firstpage} 

\pubvolume{1}
\issuenum{1}
\articlenumber{0}
\pubyear{2024}
\copyrightyear{2024}
%\externaleditor{Academic Editor: Firstname Lastname} % For journal Automation, please change Academic Editor to "Communicated by"
\datereceived{}
\daterevised{ } % Comment out if no revised date
\dateaccepted{}
\datepublished{}
%\datecorrected{} % Corrected papers include a "Corrected: XXX" date in the original paper.
%\dateretracted{} % Corrected papers include a "Retracted: XXX" date in the original paper.
\hreflink{https://doi.org/} % If needed use \linebreak
%\doinum{}
%------------------------------------------------------------------
% The following line should be uncommented if the LaTeX file is uploaded to arXiv.org
%\pdfoutput=1

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, inputenc, calc, indentfirst, fancyhdr, graphicx, epstopdf, lastpage, ifthen, lineno, float, amsmath, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, tabto, xcolor, soul, multirow, microtype, tikz, totcount, changepage, attrib, upgreek, cleveref, amsthm, hyphenat, natbib, hyperref, footmisc, url, geometry, newfloat, caption

%=================================================================
%% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition, Notation, Assumption
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Diversity
%\LSID{\url{http://}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Applied Sciences:
%\featuredapplication{Authors are encouraged to provide a concise description of the specific application or a potential application of the work. This section is not mandatory.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Data:
%\dataset{DOI number or link to the deposited data set in cases where the data set is published or set to be published separately. If the data set is submitted and will be published as a supplement to this paper in the journal Data, this field will be filled by the editors of the journal. In this case, please make sure to submit the data set as a supplement when entering your manuscript into our manuscript editorial system.}

%\datasetlicense{license under which the data set is made available (CC0, CC-BY, CC-BY-SA, CC-BY-NC, etc.)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Toxins
%\keycontribution{The breakthroughs or highlights of the manuscript. Authors can write one or two sentences to describe the most important part of the paper.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Encyclopedia
%\encyclopediadef{Instead of the abstract}
%\entrylink{The Link to this entry published on the encyclopedia platform.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Only for the journal Advances in Respiratory Medicine
%\addhighlights{yes}
%\renewcommand{\addhighlights}{%

%\noindent This is an obligatory section in â€œAdvances in Respiratory Medicineâ€, whose goal is to increase the discoverability and readability of the article via search engines and other scholars. Highlights should not be a copy of the abstract, but a simple text allowing the reader to quickly and simplified find out what the article is about and what can be cited from it. Each of these parts should be devoted up to 2~bullet points.\vspace{3pt}\\
%\textbf{What are the main findings?}
% \begin{itemize}[labelsep=2.5mm,topsep=-3pt]
% \item First bullet.
% \item Second bullet.
% \end{itemize}\vspace{3pt}
%\textbf{What is the implication of the main finding?}
% \begin{itemize}[labelsep=2.5mm,topsep=-3pt]
% \item First bullet.
% \item Second bullet.
% \end{itemize}
%}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end_preamble
\options journal,article,submit,pdftex,moreauthors
\use_default_options false
\maintain_unincluded_children false
\begin_local_layout
#Adds an endnote inset, in addition to footnotes. You will need to add
#\printendnotes in TeX-code where you want the endnotes to appear.
Format 66
Counter endnotes
    PrettyFormat "Endnote ##"
End
InsetLayout Flex:Endnote
   LyXType     custom
   LatexName   endnote
   LatexType   command
   Counter     endnotes
   Decoration  classic
   Font
     Size Small
   EndFont
   MultiPar    true
   LabelString endnote
   Requires    enotez
End
\end_local_layout
\language english
\language_package none
\inputencoding utf8
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 0
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Combining constructed artificial neural networks with parameter constraint
 techniques to achieve better generalization properties
\end_layout

\begin_layout Title Citation
Combining constructed artificial neural networks with parameter constraint
 techniques to achieve better generalization properties
\end_layout

\begin_layout Author
Ioannis G.
 Tsoulos
\begin_inset Formula $^{1,*}$
\end_inset

, Vasileios Charilogis
\end_layout

\begin_layout Author Names for PDF
Ioannis G.
 Tsoulos, Vasileios Charilogis
\end_layout

\begin_layout Author Names for Citation
Tsoulos, I.G.; Charilogis, V.; 
\end_layout

\begin_layout Address
\begin_inset Formula $^{1}$
\end_inset


\begin_inset space \quad{}
\end_inset

Department of Informatics and Telecommunications, University of Ioannina,
 Greece;itsoulos@uoi.gr
\begin_inset Newline newline
\end_inset


\begin_inset Formula $^{2}$
\end_inset


\begin_inset space \quad{}
\end_inset

Department of Informatics and Telecommunications, University of Ioannina,
 Greece; v.charilog@uoi.gr
\end_layout

\begin_layout Corresponding Author
Correspondence: itsoulos@uoi.gr
\end_layout

\begin_layout Abstract
A machine learning technology that has been used in a wide range of everyday
 problems is the recently proposed technique of constructing artificial
 neural networks with the assistance of Grammatical Evolution.
 This technique was utilized in problems from the fields of physics, chemistry,
 medicine, etc., in which it had excellent performance compared to other
 machine learning models.
 A key feature of these machine learning models is that they can both construct
 the structure of an artificial neural network efficiently and identify
 optimal values of the parameters of this network at the same time.
 However, in many cases the optimization process can become trapped in local
 minima of the error function, resulting in the construction of the artificial
 neural network not being able to be completed satisfactorily, which will
 lead to poor results in terms of test error.
 In this work, the combination of the artificial neural network construction
 method with an adapted genetic algorithm is proposed, which preserves the
 structure of the neural network that has been constructed and, in addition,
 appropriately adapts the parameters of the artificial neural network in
 order to avoid overfitting problems.
 The proposed method was applied on a wide series of datasets from real
 world problems that include classification and regression problems and
 it was compared against traditional machine learning models and the results
 are reported.
\end_layout

\begin_layout Keywords
Grammatical Evolution; Genetic Programming; Neural networks; Local Optimization
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
A basic machine learning technique with a wide range of applications in
 data classification and regression problems is artificial neural networks
 
\begin_inset CommandInset citation
LatexCommand citep
key "nn1,nn2"
literal "false"

\end_inset

.
 Artificial neural networks are parametric machine learning model, in which
 learning is achieved by effectively adjusting their parameters through
 any optimization technique.
 The optimization procedure minimizes the so - called training error of
 an artificial neural network and it is defined as: 
\begin_inset Formula 
\begin{equation}
E\left(N\left(\overrightarrow{x},\overrightarrow{w}\right)\right)=\sum_{i=1}^{M}\left(N\left(\overrightarrow{x}_{i},\overrightarrow{w}\right)-y_{i}\right)^{2}\label{eq:eq1}
\end{equation}

\end_inset

In this equation the function 
\begin_inset Formula $N\left(\overrightarrow{x},\overrightarrow{w}\right)$
\end_inset

 represents the artificial neural network which is applied on a vector 
\begin_inset Formula $\overrightarrow{x}$
\end_inset

 and the vector 
\begin_inset Formula $\overrightarrow{w}$
\end_inset

 denotes the parameter vector of the neural network.
 The set 
\begin_inset Formula $\left(\overrightarrow{x_{i}},y_{i}\right),\ i=1,...,M$
\end_inset

 represents the training set of the objective problem and the values 
\begin_inset Formula $y_{i}$
\end_inset

 are the expected outputs for each pattern 
\begin_inset Formula $\overrightarrow{x_{i}}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Artificial neural networks have been applied in a wide series of problems
 appeared in real - world problems, such as image processing 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_image"
literal "false"

\end_inset

, time series forecasting 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_timeseries"
literal "false"

\end_inset

, credit card analysis 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_credit"
literal "false"

\end_inset

, problems derived from physics 
\begin_inset CommandInset citation
LatexCommand citep
key "nnphysics1,nnphysics2"
literal "false"

\end_inset

 etc.
 Due to the widespread use of these machine learning models, a number of
 techniques have been proposed to minimize the equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:eq1"
plural "false"
caps "false"
noprefix "false"

\end_inset

, such as the Back Propagation algorithm 
\begin_inset CommandInset citation
LatexCommand citep
key "bpnn1,bpnn2"
literal "false"

\end_inset

, the RPROP algorithm 
\begin_inset CommandInset citation
LatexCommand citep
key "rpropnn-1,rpropnn-2"
literal "false"

\end_inset

, the ADAM optimization method 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_adam"
literal "false"

\end_inset

 etc.
 Also, recently a series of more advanced global optimization methods have
 been proposed to tackle the training of neural networks.
 Among them one can locate the incorporation of Genetic Algorithms 
\begin_inset CommandInset citation
LatexCommand citep
key "geneticnn1"
literal "false"

\end_inset

, the usage of the Particle Swarm Optimization (PSO) method 
\begin_inset CommandInset citation
LatexCommand citep
key "psonn"
literal "false"

\end_inset

, the Simulated Annealing method 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_siman"
literal "false"

\end_inset

, the Differential Evolution technique 
\begin_inset CommandInset citation
LatexCommand citep
key "weight_de1"
literal "false"

\end_inset

, the Artificial Bee Colony (ABC) method 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_abc"
literal "false"

\end_inset

 etc.
 Furthermore, Sexton et al suggested the usage of the tabu search algorithm
 for optimal neural network training 
\begin_inset CommandInset citation
LatexCommand citep
key "tabunn"
literal "false"

\end_inset

, Zhang et al proposed a hybrid algorithm that incorporated the PSO method
 and the Back Propagation algorithm to efficient train artificial neural
 networks 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_hybrid"
literal "false"

\end_inset

.
 Also, recently Zhao et al introduced a new Cascaded Forward Algorithm to
 train artificial neural networks 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_cascade"
literal "false"

\end_inset

.
 Furthermore, due to the rapid spread of the use of parallel computing technique
s, a series of computational techniques have emerged that exploit parallel
 computing structures for faster training of artificial neural networks
 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_gpu1,nn_gpu2"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
However, the above techniques, although extremely effective, nevertheless
 have a number of problems such as, for example, trapping in local minima
 of the error function or the phenomenon of overifitting, where the artificial
 neural network exhibits reduced performance when applied to data that was
 not present during the training process.
 The overfitting problem has been studied by many researchers that have
 proposed a series of methods to handle this problem, such as weight sharing
 
\begin_inset CommandInset citation
LatexCommand citep
key "nnsharing1,nnsharing2"
literal "true"

\end_inset

, pruning 
\begin_inset CommandInset citation
LatexCommand citep
key "nnprunning1,nnprunning2"
literal "true"

\end_inset

, early stopping 
\begin_inset CommandInset citation
LatexCommand cite
key "nnearly1,nnearly2"
literal "true"

\end_inset

, weight decaying 
\begin_inset CommandInset citation
LatexCommand cite
key "nndecay1,nndecay2"
literal "false"

\end_inset

 etc.
 Also, many researchers propose as a solution to the above problem the dynamic
 creation of the architecture of artificial neural networks using programming
 techniques.
 For example the Genetic Algorithms were proposed to create dynamically
 the optimal architecture of neural networks 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_arch1,nn_arch2"
literal "false"

\end_inset

 or the PSO method 
\begin_inset CommandInset citation
LatexCommand citep
key "nn_arch3"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
A method that was proposed relatively recently and it is based on Grammatical
 Evolution 
\begin_inset CommandInset citation
LatexCommand citep
key "ge1"
literal "false"

\end_inset

, dynamically identifies both the optimal architecture of artificial neural
 networks and the optimal values of its parameters 
\begin_inset CommandInset citation
LatexCommand citep
key "nnc"
literal "false"

\end_inset

.
 This method has been applied in a series of problems in the recent literature,
 such as problems presented in chemistry 
\begin_inset CommandInset citation
LatexCommand citep
key "nnc_amide1"
literal "false"

\end_inset

, identification of the solution of differential equations 
\begin_inset CommandInset citation
LatexCommand citep
key "nnc_de"
literal "false"

\end_inset

, medical problems 
\begin_inset CommandInset citation
LatexCommand citep
key "nnc_feas"
literal "false"

\end_inset

, problems related to education 
\begin_inset CommandInset citation
LatexCommand citep
key "nnc_student"
literal "false"

\end_inset

, autism screening 
\begin_inset CommandInset citation
LatexCommand citep
key "nnc_autism"
literal "false"

\end_inset

 etc.
 A key advantage of this technique is that it can isolate from the initial
 features of the problem those that are most important in training the model,
 thus significantly reducing the required number of parameters that need
 to be identified.
\end_layout

\begin_layout Standard
However, the method of constructing artificial neural networks can easily
 get trapped in local minima of the training error since it does not have
 any technique to avoid them.
 Furthermore, although the method can get quite close to a minimum of the
 training error, it often does not reach it since there is no technique
 in the method to train the generated parameters.
 In this technique, it is proposed to enhance the original method of constructin
g artificial neural networks by periodically applying a modified genetic
 algorithm to randomly selected chromosomes of Grammatical Evolution.
 This modified genetic algorithm preserves the architecture created by the
 Grammatical Evolution method and effectively locates the parameters of
 the artificial neural network by reducing the training error.
 In addition, the proposed genetic algorithm through appropriate penalty
 factors imposed on the fitness function prevents the artificial neural
 network from overfitting.
\end_layout

\begin_layout Standard
The remaining of this article is organized as follows: in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Method-description"
plural "false"
caps "false"
noprefix "false"

\end_inset

 the proposed method and the accompanied genetic algorithm are introduced,
 in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Results"
plural "false"
caps "false"
noprefix "false"

\end_inset

 the experimental datasets and the series of experiments conducted are listed
 and discussed thoroughly and final in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Conclusions"
plural "false"
caps "false"
noprefix "false"

\end_inset

 some conclusions are discussed.
\end_layout

\begin_layout Section
Method description
\begin_inset CommandInset label
LatexCommand label
name "sec:Method-description"

\end_inset


\end_layout

\begin_layout Standard
This section provides a details description of the original neural network
 construction method and continuous with the proposed genetic algorithm
 and concludes with the overall algorithm.
\end_layout

\begin_layout Subsection
The neural construction method 
\begin_inset CommandInset label
LatexCommand label
name "subsec:The-neural-construction"

\end_inset


\end_layout

\begin_layout Standard
The neural construction method utilizes the technique of Grammatical Evolution
 to produce artificial neural networks.
 Grammatical Evolution is an evolutionary process where the chromosomes
 are vectors of positive integers.
 These integers represent rules from a Backs - Naur form (BNF) grammar 
\begin_inset CommandInset citation
LatexCommand cite
key "bnf1"
literal "false"

\end_inset

 of the target language.

\series bold
 
\series default
The method was incorporated in various cases, such as data fitting
\series bold
 
\series default

\begin_inset CommandInset citation
LatexCommand cite
key "ge_program1,ge_program2"
literal "false"

\end_inset

, composition of music 
\begin_inset CommandInset citation
LatexCommand cite
key "ge_music"
literal "false"

\end_inset

, video games 
\begin_inset CommandInset citation
LatexCommand cite
key "ge_pacman,ge_supermario"
literal "false"

\end_inset

, energy problems 
\begin_inset CommandInset citation
LatexCommand cite
key "ge_energy"
literal "false"

\end_inset

, cryptography 
\begin_inset CommandInset citation
LatexCommand cite
key "ge_crypt"
literal "false"

\end_inset

, economics 
\begin_inset CommandInset citation
LatexCommand citep
key "ge_trading"
literal "false"

\end_inset

 etc.
 Any BNF grammar is defined as a set
\series bold
 
\begin_inset Formula $G=\left(N,T,S,P\right)$
\end_inset

 
\series default
where the letters have the following definitions:
\end_layout

\begin_layout Itemize
The set 
\begin_inset Formula $N$
\end_inset

 represents the non - terminal symbols of the grammar.
\end_layout

\begin_layout Itemize
The set 
\begin_inset Formula $T$
\end_inset

 contains the terminal symbols of the grammar.
 
\end_layout

\begin_layout Itemize
The start symbol of the grammar is denoted as 
\begin_inset Formula $S$
\end_inset

.
\end_layout

\begin_layout Itemize
The production rules of the grammar are enclosed in the set 
\begin_inset Formula $P$
\end_inset


\end_layout

\begin_layout Standard
The Grammatical Evolution production procedure initiates from the starting
 symbol 
\begin_inset Formula $S$
\end_inset

 and following a series of steps, the method creates valid programs by replacing
 non-terminal symbols with the right hand of the selected production rule.
 The selection scheme has as:
\end_layout

\begin_layout Itemize

\series bold
Read
\series default
 the next element V from the chromosome that is being processed.
\end_layout

\begin_layout Itemize

\series bold
Select
\series default
 the next production rule following the equation:Rule = V mod 
\begin_inset Formula $N_{R}$
\end_inset

.
 The symbol 
\begin_inset Formula $N_{R}$
\end_inset

 represents the total number of production rules for the under processing
 non – terminal symbol.
 
\end_layout

\begin_layout Standard
The process of producing valid programs through the Grammatical Evolution
 method is depicted graphically in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:geProcess"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename GEFC.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The Grammatical Evolution process used to produce valid programs.
\begin_inset CommandInset label
LatexCommand label
name "fig:geProcess"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

The grammar used for the neural construction procedure is shown in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:nncGrammar"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The numbers shown in parentheses are the increasing numbers of the production
 rules for each non - terminal symbol.
 The constant 
\begin_inset Formula $d$
\end_inset

 denotes the number of features in every pattern of the input dataset.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout LyX-Code
S:=<Sigval>                          (0)
\end_layout

\begin_layout LyX-Code
<Sigval>::=<Node>                    (0)
\end_layout

\begin_layout LyX-Code
           | <Node> + <Sigval>       (1)
\end_layout

\begin_layout LyX-Code
<Node>::=<Number>*sig(<Sum>+<Number>) (0)
\end_layout

\begin_layout LyX-Code
<Sum>::= <Number>*<Xlist>            (0)
\end_layout

\begin_layout LyX-Code
           |    <Sum>+<Sum>           (1)
\end_layout

\begin_layout LyX-Code
<Xlist>::= x1        (0)
\end_layout

\begin_layout LyX-Code
             |    x2  (1)
\end_layout

\begin_layout LyX-Code
             ..............
\end_layout

\begin_layout LyX-Code
             |    xd  (d-1)
\end_layout

\begin_layout LyX-Code
<Number>::= (<Dlist>.<Dlist>)        (0)
\end_layout

\begin_layout LyX-Code
             |    (-<Dlist>.<Dlist>) (1)
\end_layout

\begin_layout LyX-Code
<Dlist>::= <Digit>            (0)
\end_layout

\begin_layout LyX-Code
             | <Digit><Dlist> (1)
\end_layout

\begin_layout LyX-Code
<Digit>::= 0      (0)
\end_layout

\begin_layout LyX-Code
             |  1 (1)
\end_layout

\begin_layout LyX-Code
             ...........
\end_layout

\begin_layout LyX-Code
             |  9 (9)
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The proposed grammar for the construction of artificial neural networks
 through Grammatical Evolution.
\begin_inset CommandInset label
LatexCommand label
name "fig:nncGrammar"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

The used grammar produces artificial neural networks with the following
 form:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
N\left(\overrightarrow{x},\overrightarrow{w}\right)=\sum_{i=1}^{H}w_{(d+2)i-(d+1)}\sigma\left(\sum_{j=1}^{d}x_{j}w_{(d+2)i-(d+1)+j}+w_{(d+2)i}\right)\label{eq:nn}
\end{equation}

\end_inset

The term 
\begin_inset Formula $H$
\end_inset

 stands for the number of processing units (weights) of the neural network.
 The The function 
\begin_inset Formula $\sigma(x)$
\end_inset

 represents the sigmoid function.

\series bold
 
\series default
The total number of parameters for this network are computed through the
 following equation:
\begin_inset Formula 
\begin{equation}
n=\left(d+2\right)H
\end{equation}

\end_inset

For example the following form:
\begin_inset Formula 
\begin{equation}
N(x)=1.9\mbox{sig}\left(10.5x_{1}+3.2x_{3}+1.4\right)+2.1\mbox{sig}\left(2.2x_{2}-3.3x_{3}+3.2\right)
\end{equation}

\end_inset

denotes a produced neural network for a problem with 3 inputs 
\begin_inset Formula $\left(x_{1},x_{2},x_{3}\right)$
\end_inset

 and the number of processing nodes is 
\begin_inset Formula $H=2$
\end_inset

.
 The neural network produced can be shown graphically in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:nnExample"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename example_diagram.png
	scale 75

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
An example of a produced neural network.
\begin_inset CommandInset label
LatexCommand label
name "fig:nnExample"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
The used genetic algorithm 
\begin_inset CommandInset label
LatexCommand label
name "subsec:The-used-genetic"

\end_inset


\end_layout

\begin_layout Standard
In the original method of constructing artificial neural networks, it is
 proposed in this work to introduce the concept of local search, through
 the periodic application of a genetic algorithm which should maintain the
 structure of the neural network constructed by the original method.
 Additionally, a second goal of this genetic algorithm should be to avoid
 the problem of overfitting that could arise from simply applying a local
 optimization method to the previous artificial neural network.
 For the first goal of the modified genetic algorithm consider the example
 neural network shown before:
\begin_inset Formula 
\begin{equation}
N(x)=1.9\mbox{sig}\left(10.5x_{1}+3.2x_{3}+1.4\right)+2.1\mbox{sig}\left(2.2x_{2}-3.3x_{3}+3.2\right)
\end{equation}

\end_inset

The weight vector 
\begin_inset Formula $\overrightarrow{w}$
\end_inset

 for this neural network would be 
\begin_inset Formula 
\begin{equation}
\overrightarrow{w}=\left[1.9,10.5,0.0,3.2,1.4,2.1,0.0,2.2,-3.3,3.2\right]\label{eq:exampleNN}
\end{equation}

\end_inset

In order to protect the structure of this artificial neural network, the
 modified genetic algorithm should allow changes in the parameters of this
 network within a value interval, which can be considered to be the pair
 of vectors 
\begin_inset Formula $\left[\overrightarrow{L,}\overrightarrow{R}\right]$
\end_inset

.
 The elements for the vector 
\begin_inset Formula $\overrightarrow{L}$
\end_inset

 are defined as 
\begin_inset Formula 
\begin{equation}
L_{i}=-F\times\left|w_{i}\right|,\ i=1,\ldots,n\label{eq:createL}
\end{equation}

\end_inset

where 
\begin_inset Formula $F$
\end_inset

 is positive number with 
\begin_inset Formula $F>1$
\end_inset

.
 Likewise the right bound for the parameters 
\begin_inset Formula $\overrightarrow{R}$
\end_inset

 is defined from the following equation:
\begin_inset Formula 
\begin{equation}
R_{i}=F\times\left|w_{i}\right|,i=1,\ldots,n\label{eq:createR}
\end{equation}

\end_inset

For the example weight vector of equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:exampleNN"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and for 
\begin_inset Formula $F=2$
\end_inset

 the following vectors are used:
\begin_inset Formula 
\[
\begin{array}{ccc}
L & = & \left[-3.8,-21.0,0.0,-6.4,-2.8,-4.2,0.0,-4.4,-6.6,-6.4\right]\\
R & = & \left[\ \ \ 3.8,\ \ \ 21.0,0.0,\ \ \ 6.4,\ \ \ \ 2.8,\ \ \ \ 4.2,0.0,\ \ \ 4.4,\ \ \ 6.6,\ \ \ \ 6.4\right]
\end{array}
\]

\end_inset

The modified genetic algorithm should also prevent the artificial neural
 networks it trains from the phenomenon of overfitting, which would lead
 to poor results on the test dataset.
 For this reason a quantity derived from the publication of Anastasopoulos
 et al.
 
\begin_inset CommandInset citation
LatexCommand citep
key "nnt_bound"
literal "false"

\end_inset

 is utilized here.
 The sigmoid function, that is used as the activation function of neural
 networks is defined as:
\begin_inset Formula 
\begin{equation}
\sigma(x)=\frac{1}{1+\exp(-x)}
\end{equation}

\end_inset

A plot for this function is shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:plotsigma"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename sig.eps
	scale 75

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Plot of the sigmoid function 
\begin_inset Formula $\sigma(x)$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:plotsigma"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset

As is clear from the equation and the figure, as the value of the parameter
 x increases, the function tends very quickly to 1.
 On the other hand, the function will take values very close to 0 as the
 parameter x decreases.
 This means that the function very quickly loses the generalizing abilities
 it has and therefore large changes in the value of the parameter x will
 not cause proportional variations in the value of the sigmoid function.
 Therefore, the quantity 
\begin_inset Formula $B\left(N\left(\overrightarrow{x},\overrightarrow{w}\right),a\right)$
\end_inset

 was introduced in that paper to measure this effect.
 This quantity is calculated through the process of Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:CalculationBound"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The algorithm used to calculate the bounding quantity for neural network
 
\begin_inset Formula $N(x,w)$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "alg:CalculationBound"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
function
\series default
 
\begin_inset Formula $\mbox{evalB}\left(N\left(\overrightarrow{x},\overrightarrow{w}\right),a\right)$
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
Inputs
\series default
: The Neural network 
\begin_inset Formula $N\left(\overrightarrow{x},\overrightarrow{w}\right)$
\end_inset

 and the double precision value 
\begin_inset Formula $a,\ a>1$
\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 
\begin_inset Formula $s=0$
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
For
\series default
 
\begin_inset Formula $i=1..H$
\end_inset

 
\series bold
Do
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
For
\series default
 
\begin_inset Formula $j=1..M$
\end_inset

 
\series bold
Do
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Calculate
\series default
 
\begin_inset Formula $v=\sum_{kT=1}^{d}w_{(d+2)i-(d+i)+k}x_{jk}+w_{(d+2)i}$
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
If
\series default
 
\begin_inset Formula $\left|v\right|>a$
\end_inset

 
\series bold
set
\series default
 
\begin_inset Formula $s=s+1$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
EndFor
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
EndFor
\end_layout

\begin_layout Enumerate

\series bold
Return
\series default
 
\begin_inset Formula $\frac{s}{H\star M}$
\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
End Function
\end_layout

\end_inset

The overall proposed modified genetic algorithm is shown in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:The-modified-Genetic"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The modified Genetic Algorithm.
\begin_inset CommandInset label
LatexCommand label
name "alg:The-modified-Genetic"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
Function
\series default
 
\begin_inset Formula $\mbox{mGA}\left(\overrightarrow{L},\overrightarrow{R,}a,\lambda\right)$
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
Input
\series default
s: The bound vectors 
\begin_inset Formula $\overrightarrow{L,}\overrightarrow{R}$
\end_inset

 and the bounding factor 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $\lambda$
\end_inset

 a positive value with 
\begin_inset Formula $\lambda>1$
\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 as 
\begin_inset Formula $N_{K}$
\end_inset

the number of allowed generations and as 
\begin_inset Formula $N_{G}$
\end_inset

 the number of used chromosomes.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 as 
\begin_inset Formula $p_{S}$
\end_inset

 the selection rate and as 
\begin_inset Formula $p_{M}$
\end_inset

 the mutation rate.
\end_layout

\begin_layout Enumerate

\series bold
Initialize
\series default
 
\begin_inset Formula $N_{G}$
\end_inset

 chromosomes inside the bounding boxes 
\begin_inset Formula $\overrightarrow{L,}\overrightarrow{R}$
\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 
\begin_inset Formula $k=0$
\end_inset

, the generation number.
\end_layout

\begin_layout Enumerate

\series bold
For
\series default
 
\begin_inset Formula $i=1,\ldots,N_{G}$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "enu:For"

\end_inset


\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Obtain
\series default
 the corresponding neural network 
\begin_inset Formula $N_{i}\left(\overrightarrow{x},\overrightarrow{g_{i}}\right)$
\end_inset

 for the chromosome 
\begin_inset Formula $g_{i}$
\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 
\begin_inset Formula $e_{i}=\sum_{j=1}^{M}\left(N_{i}\left(\overrightarrow{x}_{j},\overrightarrow{w_{i}}\right)-y_{j}\right)^{2}$
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 
\begin_inset Formula $B_{i}=\mbox{eval}\left(N_{i}\left(\overrightarrow{x},\overrightarrow{g_{i}}\right),a\right)$
\end_inset

 using the algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:CalculationBound"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 
\begin_inset Formula $f_{i}=e_{i}\times\left(1+\lambda B_{i}^{2}\right)$
\end_inset

 as the fitness value of chromosome 
\begin_inset Formula $g_{i}$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
End For
\end_layout

\begin_layout Enumerate

\series bold
Select
\series default
 the best 
\begin_inset Formula $\left(1-p_{s}\right)\times N_{G}$
\end_inset

 chromosomes, that will be copied intact to the next generation.
 The remaining will be substituted by individuals produced by crossover
 and mutation.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 
\begin_inset Formula $k=k+1$
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
If
\series default
 
\begin_inset Formula $k\le N_{K}$
\end_inset

 
\series bold
goto
\series default
 step 
\begin_inset CommandInset ref
LatexCommand ref
reference "enu:For"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Plain Layout

\series bold
End function
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
The overall algorithm
\end_layout

\begin_layout Standard
The overall algorithm uses the procedures presented previously to achieve
 greater accuracy in calculations as well as to avoid overfitting phenomena.
 The steps of the overall algorithm have as follows:
\end_layout

\begin_layout Enumerate

\series bold
Initialization
\series default
.
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Set
\series default
 as 
\begin_inset Formula $N_{C}$
\end_inset

 the number of chromosomes for the Grammatical Evolution procedure and as
 
\begin_inset Formula $N_{G}$
\end_inset

 the maximum number of allowed generations.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 as 
\begin_inset Formula $p_{S}$
\end_inset

 the selection rate and as 
\begin_inset Formula $p_{M}$
\end_inset

 the mutation rate.
\end_layout

\begin_layout Enumerate

\series bold
Let
\series default
 
\begin_inset Formula $N_{I}$
\end_inset

 be the number of chromosomes to which the modified genetic algorithm will
 be periodically applied.
 
\end_layout

\begin_layout Enumerate

\series bold
Let
\series default
 
\begin_inset Formula $N_{T}$
\end_inset

 be the number of generations that will pass before applying the modified
 genetic algorithm to randomly selected chromosomes.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 the weight factor 
\begin_inset Formula $F$
\end_inset

 with 
\begin_inset Formula $F>1$
\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 the values 
\begin_inset Formula $N_{K},\ a,\ \lambda$
\end_inset

 used in the modified genetic algorithm.
\end_layout

\begin_layout Enumerate

\series bold
Initialize
\series default
 randomly the 
\begin_inset Formula $N_{C}$
\end_inset

 chromosomes as sets of randomly selected integers.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 the generation number 
\begin_inset Formula $k=0$
\end_inset

 
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Fitness Calculation
\series default
.
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
For
\series default
 
\begin_inset Formula $i=1,\ldots,N_{C}$
\end_inset

 
\series bold
do
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Obtain
\series default
 the chromosome 
\begin_inset Formula $g_{i}$
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
Create
\series default
 the corresponding neural network 
\begin_inset Formula $N_{i}\left(\overrightarrow{x},\overrightarrow{w}\right)$
\end_inset

 using Grammatical Evolution.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 the fitness value 
\begin_inset Formula $f_{i}=\sum_{j=1}^{M}\left(N_{i}\left(\overrightarrow{x}_{j},\overrightarrow{w}\right)-y_{j}\right)^{2}$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
End For
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Genetic Operations
\series default
.
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Select
\series default
 the best 
\begin_inset Formula $\left(1-p_{s}\right)\times N_{G}$
\end_inset

 chromosomes, that will be copied intact to the next generation.
 
\end_layout

\begin_layout Enumerate

\series bold
Create
\series default
 
\begin_inset Formula $p_{S}N$
\end_inset

 chromosomes using one - point crossover.
 For every couple 
\begin_inset Formula $\left(c_{1},c_{2}\right)$
\end_inset

 of produced offsprings two distinct chromosomes are selected from the current
 population using tournament selection.
 An example of the one - point crossover procedure is shown graphically
 in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:onePoint"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Enumerate
For every chromosome and for each element select a random number 
\begin_inset Formula $r\le1$
\end_inset

.
 Alter the current element when 
\begin_inset Formula $r\le p_{M}$
\end_inset


\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Local search.
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
If
\series default
 
\begin_inset Formula $k\ \mbox{mod}\ N_{T}=0$
\end_inset

 
\series bold
then
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Set
\series default
 
\begin_inset Formula $S=\left\{ g_{r_{1}},g_{r_{2}},\ldots,g_{r_{N_{I}}}\right\} $
\end_inset

 a group of 
\begin_inset Formula $N_{I}$
\end_inset

 randomly selected chromosomes from the genetic population.
\end_layout

\begin_layout Enumerate

\series bold
For
\series default
 every member 
\begin_inset Formula $g\in S$
\end_inset

 
\series bold
do
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Obtain
\series default
 the corresponding neural network 
\begin_inset Formula $N_{g}\left(\overrightarrow{x},\overrightarrow{w}\right)$
\end_inset

 for the chromosome 
\begin_inset Formula $g$
\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Create
\series default
 the left bound vector 
\begin_inset Formula $\overrightarrow{L_{g}}$
\end_inset

 and the right bound vector 
\begin_inset Formula $\overrightarrow{R_{g}}$
\end_inset

 for 
\begin_inset Formula $g$
\end_inset

 using the equations 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:createL"
plural "false"
caps "false"
noprefix "false"

\end_inset

,
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:createR"
plural "false"
caps "false"
noprefix "false"

\end_inset

 respectively.
\end_layout

\begin_layout Enumerate

\series bold
Set
\series default
 
\begin_inset Formula $g=\mbox{mga}\left(\overrightarrow{L_{g}},\overrightarrow{R_{g},}a,\lambda\right)$
\end_inset

 using the steps of algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:The-modified-Genetic"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
End For
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Endif
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Termination Check
\series default
.
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Set
\series default
 
\begin_inset Formula $k=k+1$
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
If
\series default
 
\begin_inset Formula $k\le N_{G}$
\end_inset

 goto 
\series bold
Fitness Calculation
\series default
.
\end_layout

\end_deeper
\begin_layout Enumerate

\series bold
Application to the test set
\series default
.
\end_layout

\begin_deeper
\begin_layout Enumerate

\series bold
Obtain
\series default
 the chromosome 
\begin_inset Formula $g^{*}$
\end_inset

 with the lowest fitness value and create through Grammatical Evolution
 the corresponding neural network 
\begin_inset Formula $N^{*}\left(\overrightarrow{x},\overrightarrow{w}\right)$
\end_inset


\end_layout

\begin_layout Enumerate

\series bold
Apply
\series default
 the neural network 
\begin_inset Formula $N^{*}\left(\overrightarrow{x},\overrightarrow{w}\right)$
\end_inset

 and report the corresponding error value.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename onepoint_crossover.eps
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
An example of the one - point crossover procedure.
\begin_inset CommandInset label
LatexCommand label
name "fig:onePoint"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Experimental results
\begin_inset CommandInset label
LatexCommand label
name "sec:Results"

\end_inset


\end_layout

\begin_layout Standard
The validation of the proposed method was performed using a wide series
 of classification and regression datasets, available from various sources
 from the Internet.
 These datasets were downloaded from:
\end_layout

\begin_layout Enumerate
The UCI database, 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://archive.ics.uci.edu/
\end_layout

\end_inset

(accessed on 22 January 2025)
\begin_inset CommandInset citation
LatexCommand citep
key "uci"
literal "false"

\end_inset


\end_layout

\begin_layout Enumerate
The Keel website, 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://sci2s.ugr.es/keel/datasets.php
\end_layout

\end_inset

(accessed on 22 January 2025)
\begin_inset CommandInset citation
LatexCommand cite
key "Keel"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate
The Statlib URL 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://lib.stat.cmu.edu/datasets/index
\end_layout

\end_inset

(accessed on 22 January 2025).
 
\end_layout

\begin_layout Subsection
Experimental datasets 
\end_layout

\begin_layout Standard
The following datasets were utilized in the conducted experiments:
\end_layout

\begin_layout Enumerate

\series bold
Appendictis
\series default
 which is a medical dataset 
\begin_inset CommandInset citation
LatexCommand cite
key "appendicitis"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Enumerate

\series bold
Alcohol
\series default
, which is dataset regarding alcohol consumption 
\begin_inset CommandInset citation
LatexCommand citep
key "alcohol"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Enumerate

\series bold
Australian
\series default
, which is a dataset produced from various bank transactions 
\begin_inset CommandInset citation
LatexCommand citep
key "australian"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Balance
\series default
 dataset 
\begin_inset CommandInset citation
LatexCommand cite
key "balance"
literal "false"

\end_inset

, produced from various psychological experiments.
\end_layout

\begin_layout Enumerate

\series bold
Cleveland
\series default
, a medical dataset which was discussed in a series of papers 
\begin_inset CommandInset citation
LatexCommand citep
key "cleveland1,cleveland2"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Enumerate

\series bold
Circular
\series default
 dataset, which is an artificial dataset.
\end_layout

\begin_layout Enumerate

\series bold
Dermatology
\series default
, a medical dataset for dermatology problems 
\begin_inset CommandInset citation
LatexCommand citep
key "dermatology"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Ecoli
\series default
, which is related to protein problems 
\begin_inset CommandInset citation
LatexCommand citep
key "ecoli"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Glass
\series default
 dataset, that contains measurements from glass component analysis.
 
\end_layout

\begin_layout Enumerate

\series bold
Haberman
\series default
, a medical dataset related to breast cancer.
\end_layout

\begin_layout Enumerate

\series bold
Hayes-roth
\series default
 dataset 
\begin_inset CommandInset citation
LatexCommand citep
key "hayes-roth"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Heart
\series default
, which is a dataset related to heart diseases 
\begin_inset CommandInset citation
LatexCommand citep
key "heart"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
HeartAttack
\series default
, which is a medical dataset for the detection of heart diseases
\end_layout

\begin_layout Enumerate

\series bold
Hepatitis
\series default
, a medical dataset related to the hepatitis.
 
\end_layout

\begin_layout Enumerate

\series bold
Housevotes
\series default
, a dataset which is related to the Congressional voting in USA 
\begin_inset CommandInset citation
LatexCommand citep
key "housevotes"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Ionosphere
\series default
, a dataset that contains measurements from the ionosphere 
\begin_inset CommandInset citation
LatexCommand citep
key "ion1,ion2"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Liverdisorder
\series default
, a medical dataset that was studied thoroughly in a series of papers
\begin_inset CommandInset citation
LatexCommand citep
key "liver,liver1"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Lymography
\series default
 
\begin_inset CommandInset citation
LatexCommand citep
key "lymography"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Mammographic
\series default
, which is a medical dataset used for the prediction of breast cancer 
\begin_inset CommandInset citation
LatexCommand citep
key "mammographic"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Parkinsons
\series default
, which is a medical dataset used for the detection of Parkinson's disease
 
\begin_inset CommandInset citation
LatexCommand citep
key "parkinsons1,parkinsons2"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Pima
\series default
, which is a medical dataset for the detection of diabetes
\begin_inset CommandInset citation
LatexCommand citep
key "pima"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Phoneme
\series default
, a dataset that contains sound measurements.
\end_layout

\begin_layout Enumerate

\series bold
Popfailures
\series default
, a dataset related to experiments regarding climate 
\begin_inset CommandInset citation
LatexCommand citep
key "popfailures"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
(OK)Regions2
\series default
, a medical dataset used for the detection of issues in the liver 
\begin_inset CommandInset citation
LatexCommand citep
key "regions2"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Saheart
\series default
, used for the detection of heart diseases
\begin_inset CommandInset citation
LatexCommand citep
key "saheart"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Segment
\series default
 dataset 
\begin_inset CommandInset citation
LatexCommand cite
key "segment"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Statheart
\series default
, a medical dataset used for the detection of heart diseases.
\end_layout

\begin_layout Enumerate

\series bold
Spiral
\series default
, which is an artificial dataset.
\end_layout

\begin_layout Enumerate

\series bold
Student
\series default
, a dataset concerning experiments in schools 
\begin_inset CommandInset citation
LatexCommand citep
key "student"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Tae
\series default
, used to evaluate teaching performance.
\end_layout

\begin_layout Enumerate

\series bold
Transfusion
\series default
, which is a medical dataset 
\begin_inset CommandInset citation
LatexCommand citep
key "transfusion"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Wdbc
\series default
, a medical dataset which is used to detect breast cancer 
\begin_inset CommandInset citation
LatexCommand citep
key "wdbc1,wdbc2"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Wine
\series default
, a dataset used to detect the quality of wines 
\begin_inset CommandInset citation
LatexCommand citep
key "wine1,wine2"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
EEG
\series default
 dataset, which is a medical dataset about EEG recordings
\begin_inset CommandInset citation
LatexCommand citep
key "eeg1,eeg2"
literal "false"

\end_inset

.
 The following cases from this dataset were adopted here: Z_F_S, ZO_NF_S,
 ZONF_S and Z_O_N_F_S.
\end_layout

\begin_layout Enumerate

\series bold
Zoo
\series default
, a dataset used for animal classification 
\begin_inset CommandInset citation
LatexCommand citep
key "zoo"
literal "false"

\end_inset

 .
\end_layout

\begin_layout Standard
Additionally, the following series of regression datasets was adopted:
\end_layout

\begin_layout Enumerate

\series bold
Abalone
\series default
, a dataset related to the age of abalones 
\begin_inset CommandInset citation
LatexCommand citep
key "abalone"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Airfoil
\series default
, a dataset provided by NASA 
\begin_inset CommandInset citation
LatexCommand citep
key "airfoil"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Auto
\series default
, a dataset related to the fuel consumption of cars.
\end_layout

\begin_layout Enumerate

\series bold
BK
\series default
, a dataset which is related to basketball games.
 
\end_layout

\begin_layout Enumerate

\series bold
BL
\series default
, a dataset related to electricity experiments.
\end_layout

\begin_layout Enumerate

\series bold
Baseball
\series default
, a dataset used to estimate the income of baseball players.
\end_layout

\begin_layout Enumerate

\series bold
Concrete
\series default
, a civil engineering dataset 
\begin_inset CommandInset citation
LatexCommand citep
key "concrete"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
DEE
\series default
, used for the prediction of electricity prices.
\end_layout

\begin_layout Enumerate

\series bold
Friedman
\series default
, an artificial dataset
\begin_inset CommandInset citation
LatexCommand citep
key "friedman"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
FY, 
\series default
this dataset used in experiments regarding the longevity of fruit flies.
 
\end_layout

\begin_layout Enumerate

\series bold
HO
\series default
, a dataset with 13 features obtained from the STATLIB repository.
\end_layout

\begin_layout Enumerate

\series bold
Housing
\series default
, used to estimate the price of houses 
\begin_inset CommandInset citation
LatexCommand citep
key "housing"
literal "false"

\end_inset

.
\end_layout

\begin_layout Enumerate

\series bold
Laser
\series default
, used in a series of laser experiments.
\end_layout

\begin_layout Enumerate

\series bold
LW
\series default
, a dataset used to detect the weight of babes.
\end_layout

\begin_layout Enumerate

\series bold
Mortgage
\series default
, an dataset related to economic measurements.
\end_layout

\begin_layout Enumerate

\series bold
PL
\end_layout

\begin_layout Enumerate

\series bold
Plastic
\series default
, a dataset related to problems regarding pressure on plastics.
\end_layout

\begin_layout Enumerate

\series bold
Quake
\series default
, a dataset used to measure earthquakes.
\end_layout

\begin_layout Enumerate

\series bold
SN
\series default
, a dataset related to trellising and pruning.
\end_layout

\begin_layout Enumerate

\series bold
Stock
\series default
, a dataset related to the prices of stocks.
\end_layout

\begin_layout Enumerate

\series bold
Treasury
\series default
, which is related to economics.
\end_layout

\begin_layout Subsection
Experiments 
\end_layout

\begin_layout Subsection
Experiments with the parameter 
\begin_inset Formula $F$
\end_inset


\end_layout

\begin_layout Subsection
Experiments with the parameter 
\begin_inset Formula $N_{I}$
\end_inset


\end_layout

\begin_layout Section
Conclusions
\begin_inset CommandInset label
LatexCommand label
name "sec:Conclusions"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace 6pt
\end_inset


\end_layout

\begin_layout Author Contributions
I.G.T.
 conceptualized the idea and methodology, supervised the technical aspects
 related to the software, and contributed to manuscript preparation.
 Also, I.G.T conducted the experiments using various datasets and V.C.
 performed statistical analysis.
 I.G.T and V.C prepared the manuscript for publication.
 All authors have reviewed and endorsed the conclusive version of the manuscript.
\end_layout

\begin_layout Funding
This research received no external funding.
\end_layout

\begin_layout Institutional Review
Not applicable.
\end_layout

\begin_layout Institutional Review
Not applicable.
\end_layout

\begin_layout Institutional Review
Not applicable.
\end_layout

\begin_layout Acknowledgments
This research has been financed by the European Union : Next Generation
 EU through the Program Greece 2.0 National Recovery and Resilience Plan
 , under the call RESEARCH – CREATE – INNOVATE, project name “iCREW: Intelligent
 small craft simulator for advanced crew training using Virtual Reality
 techniques" (project code:TAEDK-06195).
\end_layout

\begin_layout Conflicts of Interest
The authors declare no conflicts of interest.
\end_layout

\begin_layout Begin Whole Page

\end_layout

\begin_layout References Title
References
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn1"
literal "true"

\end_inset

Abiodun, O.
 I., Jantan, A., Omolara, A.
 E., Dada, K.
 V., Mohamed, N.
 A., & Arshad, H.
 (2018).
 State-of-the-art in artificial neural network applications: A survey.
 Heliyon, 4(11).
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn2"
literal "true"

\end_inset

Suryadevara, S., & Yanamala, A.
 K.
 Y.
 (2021).
 A Comprehensive Overview of Artificial Neural Networks: Evolution, Architecture
s, and Applications.
 Revista de Inteligencia Artificial en Medicina, 12(1), 51-76.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_image"
literal "false"

\end_inset

M.
 Egmont-Petersen, D.
 de Ridder, H.
 Handels, Image processing with neural networks—a review, Pattern Recognition
 
\series bold
35
\series default
, pp.
 2279-2301, 2002.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_timeseries"
literal "false"

\end_inset

G.Peter Zhang, Time series forecasting using a hybrid ARIMA and neural network
 model, Neurocomputing 
\series bold
50
\series default
, pp.
 159-175, 2003.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_credit"
literal "false"

\end_inset

Z.
 Huang, H.
 Chen, C.-Jung Hsu, W.-Hwa Chen, S.
 Wu, Credit rating analysis with support vector machines and neural networks:
 a market comparative study, Decision Support Systems 
\series bold
37
\series default
, pp.
 543-558, 2004.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnphysics1"
literal "false"

\end_inset

P.
 Baldi, K.
 Cranmer, T.
 Faucett et al, Parameterized neural networks for high-energy physics, Eur.
 Phys.
 J.
 C 
\series bold
76
\series default
, 2016.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnphysics2"
literal "true"

\end_inset

Baldi, P., Cranmer, K., Faucett, T., Sadowski, P., & Whiteson, D.
 (2016).
 Parameterized neural networks for high-energy physics.
 The European Physical Journal C, 76(5), 1-7.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "bpnn1"
literal "false"

\end_inset

Vora, K., & Yagnik, S.
 (2014).
 A survey on backpropagation algorithms for feedforward neural networks.
 International Journal of Engineering Development and Research, 1(3), 193-197.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "bpnn2"
literal "false"

\end_inset

K.
 Vora, S.
 Yagnik, A survey on backpropagation algorithms for feedforward neural networks,
 International Journal of Engineering Development and Research 
\series bold
1
\series default
, pp.
 193-197, 2014.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "rpropnn-1"
literal "false"

\end_inset

Pajchrowski, T., Zawirski, K., & Nowopolski, K.
 (2014).
 Neural speed controller trained online by means of modified RPROP algorithm.
 IEEE transactions on industrial informatics, 11(2), 560-568.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "rpropnn-2"
literal "false"

\end_inset

Hermanto, R.
 P.
 S., & Nugroho, A.
 (2018).
 Waiting-time estimation in bank customer queues using RPROP neural networks.
 Procedia Computer Science, 135, 35-42.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_adam"
literal "false"

\end_inset

D.
 P.
 Kingma, J.
 L.
 Ba, ADAM: a method for stochastic optimization, in: Proceedings of the
 3rd International Conference on Learning Representations (ICLR 2015), pp.
 1–15, 2015.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "geneticnn1"
literal "false"

\end_inset

Reynolds, J., Rezgui, Y., Kwan, A., & Piriou, S.
 (2018).
 A zone-level, building energy optimisation combining an artificial neural
 network, a genetic algorithm, and model predictive control.
 Energy, 151, 729-739.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "psonn"
literal "false"

\end_inset

Das, G., Pattnaik, P.
 K., & Padhy, S.
 K.
 (2014).
 Artificial neural network trained by particle swarm optimization for non-linear
 channel equalization.
 Expert Systems with Applications, 41(7), 3491-3496.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_siman"
literal "false"

\end_inset

Sexton, R.
 S., Dorsey, R.
 E., & Johnson, J.
 D.
 (1999).
 Beyond backpropagation: using simulated annealing for training neural networks.
 Journal of Organizational and End User Computing (JOEUC), 11(3), 3-10.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "weight_de1"
literal "false"

\end_inset

Wang, L., Zeng, Y., & Chen, T.
 (2015).
 Back propagation neural network with adaptive differential evolution algorithm
 for time series forecasting.
 Expert Systems with Applications, 42(2), 855-863.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_abc"
literal "false"

\end_inset

Karaboga, D., & Akay, B.
 (2007, June).
 Artificial bee colony (ABC) algorithm on training artificial neural networks.
 In 2007 IEEE 15th Signal Processing and Communications Applications (pp.
 1-4).
 IEEE.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "tabunn"
literal "false"

\end_inset

R.S.
 Sexton, B.
 Alidaee, R.E.
 Dorsey, J.D.
 Johnson, Global optimization for artificial neural networks: A tabu search
 application.
 European Journal of Operational Research 
\series bold
106
\series default
, pp.
 570-584, 1998.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_hybrid"
literal "false"

\end_inset

J.-R.
 Zhang, J.
 Zhang, T.-M.
 Lok, M.R.
 Lyu, A hybrid particle swarm optimization–back-propagation algorithm for
 feedforward neural network training, Applied Mathematics and Computation
 
\series bold
185
\series default
, pp.
 1026-1037, 2007.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_cascade"
literal "false"

\end_inset

G.
 Zhao, T.
 Wang, Y.
 Jin, C.
 Lang, Y.
 Li, H.
 Ling, The Cascaded Forward algorithm for neural network training, Pattern
 Recognition 
\series bold
161
\series default
, 111292, 2025.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_gpu1"
literal "false"

\end_inset

K-Su Oh, K.
 Jung, GPU implementation of neural networks, Pattern Recognition 
\series bold
37
\series default
, pp.
 1311-1314, 2004.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_gpu2"
literal "false"

\end_inset

M.
 Zhang, K.
 Hibi, J.
 Inoue, GPU-accelerated artificial neural network potential for molecular
 dynamics simulation, Computer Physics Communications 
\series bold
285
\series default
, 108655, 2023.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnsharing1"
literal "true"

\end_inset

S.J.
 Nowlan and G.E.
 Hinton, Simplifying neural networks by soft weight sharing, Neural Computation
 4, pp.
 473-493, 1992.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnsharing2"
literal "false"

\end_inset

Nowlan, S.
 J., & Hinton, G.
 E.
 (2018).
 Simplifying neural networks by soft weight sharing.
 In The mathematics of generalization (pp.
 373-394).
 CRC Press.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnprunning1"
literal "true"

\end_inset

S.J.
 Hanson and L.Y.
 Pratt, Comparing biases for minimal network construction with back propagation,
 In D.S.
 Touretzky (Ed.), Advances in Neural Information Processing Systems, Volume
 1, pp.
 177-185, San Mateo, CA: Morgan Kaufmann, 1989.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnprunning2"
literal "false"

\end_inset

M.
 Augasta and T.
 Kathirvalavakumar, Pruning algorithms of neural networks — a comparative
 study, Central European Journal of Computer Science, 2003.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnearly1"
literal "false"

\end_inset

Lutz Prechelt, Automatic early stopping using cross validation: quantifying
 the criteria, Neural Networks 
\series bold
11
\series default
, pp.
 761-767, 1998.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnearly2"
literal "false"

\end_inset

X.
 Wu and J.
 Liu, A New Early Stopping Algorithm for Improving Neural Network Generalization
, 2009 Second International Conference on Intelligent Computation Technology
 and Automation, Changsha, Hunan, 2009, pp.
 15-18.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nndecay1"
literal "false"

\end_inset

N.
 K.
 Treadgold and T.
 D.
 Gedeon, Simulated annealing and weight decay in adaptive learning: the
 SARPROP algorithm,IEEE Transactions on Neural Networks 
\series bold
9
\series default
, pp.
 662-668, 1998.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nndecay2"
literal "false"

\end_inset

M.
 Carvalho and T.
 B.
 Ludermir, Particle Swarm Optimization of Feed-Forward Neural Networks with
 Weight Decay, 2006 Sixth International Conference on Hybrid Intelligent
 Systems (HIS'06), Rio de Janeiro, Brazil, 2006, pp.
 5-5.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_arch1"
literal "false"

\end_inset

J.
 Arifovic, R.
 Gençay, Using genetic algorithms to select architecture of a feedforward
 artificial neural network, Physica A: Statistical Mechanics and its Application
s 
\series bold
289
\series default
, pp.
 574-594, 2001.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_arch2"
literal "false"

\end_inset

P.G.
 Benardos, G.C.
 Vosniakos, Optimizing feedforward artificial neural network architecture,
 Engineering Applications of Artificial Intelligence 
\series bold
20
\series default
, pp.
 365-382, 2007.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nn_arch3"
literal "false"

\end_inset

B.A.
 Garro, R.A.
 Vázquez, Designing Artificial Neural Networks Using Particle Swarm Optimization
 Algorithms, Computational Intelligence and Neuroscience, 369298, 2015.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ge1"
literal "true"

\end_inset

M.
 O’Neill, C.
 Ryan, Grammatical evolution, IEEE Trans.
 Evol.
 Comput.
 
\series bold
5,
\series default
pp.
 349–358, 2001.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnc"
literal "false"

\end_inset

I.G.
 Tsoulos, D.
 Gavrilis, E.
 Glavas, Neural network construction and training using grammatical evolution,
 Neurocomputing 
\series bold
72
\series default
, pp.
 269-277, 2008.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnc_amide1"
literal "false"

\end_inset

G.V.
 Papamokos, I.G.
 Tsoulos, I.N.
 Demetropoulos, E.
 Glavas, Location of amide I mode of vibration in computed data utilizing
 constructed neural networks, Expert Systems with Applications 
\series bold
36
\series default
, pp.
 12210-12213, 2009.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnc_de"
literal "false"

\end_inset

I.G.
 Tsoulos, D.
 Gavrilis, E.
 Glavas, Solving differential equations with constructed neural networks,
 Neurocomputing 
\series bold
72
\series default
, pp.
 2385-2391, 2009.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnc_feas"
literal "false"

\end_inset

I.G.
 Tsoulos, G.
 Mitsi, A.
 Stavrakoudis, S.
 Papapetropoulos, Application of Machine Learning in a Parkinson's Disease
 Digital Biomarker Dataset Using Neural Network Construction (NNC) Methodology
 Discriminates Patient Motor Status, Frontiers in ICT 6, 10, 2019.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnc_student"
literal "false"

\end_inset

V.
 Christou, I.G.
 Tsoulos, V.
 Loupas, A.T.
 Tzallas, C.
 Gogos, P.S.
 Karvelis, N.
 Antoniadis, E.
 Glavas, N.
 Giannakeas, Performance and early drop prediction for higher education
 students using machine learning, Expert Systems with Applications 
\series bold
225
\series default
, 120079, 2023.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnc_autism"
literal "false"

\end_inset

E.I.
 Toki, J.
 Pange, G.
 Tatsis, K.
 Plachouras, I.G.
 Tsoulos, Utilizing Constructed Neural Networks for Autism Screening, Applied
 Sciences 
\series bold
14
\series default
, 3053, 2024.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "bnf1"
literal "false"

\end_inset

J.
 W.
 Backus.
 The Syntax and Semantics of the Proposed International Algebraic Language
 of the Zurich ACM-GAMM Conference.
 Proceedings of the International Conference on Information Processing,
 UNESCO, 1959, pp.125-132.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ge_program1"
literal "false"

\end_inset

C.
 Ryan, J.
 Collins, M.
 O’Neill, Grammatical evolution: Evolving programs for an arbitrary language.
 In: Banzhaf, W., Poli, R., Schoenauer, M., Fogarty, T.C.
 (eds) Genetic Programming.
 EuroGP 1998.
 Lecture Notes in Computer Science, vol 1391.
 Springer, Berlin, Heidelberg, 1998.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ge_program2"
literal "false"

\end_inset

M.
 O’Neill, M., C.
 Ryan, Evolving Multi-line Compilable C Programs.
 In: Poli, R., Nordin, P., Langdon, W.B., Fogarty, T.C.
 (eds) Genetic Programming.
 EuroGP 1999.
 Lecture Notes in Computer Science, vol 1598.
 Springer, Berlin, Heidelberg, 1999.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ge_music"
literal "false"

\end_inset

A.O.
 Puente, R.
 S.
 Alfonso, M.
 A.
 Moreno, Automatic composition of music by means of grammatical evolution,
 In: APL '02: Proceedings of the 2002 conference on APL: array processing
 languages: lore, problems, and applications July 2002 Pages 148–155.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ge_pacman"
literal "false"

\end_inset

E.
 Galván-López, J.M.
 Swafford, M.
 O’Neill, A.
 Brabazon, Evolving a Ms.
 PacMan Controller Using Grammatical Evolution.
 In: , et al.
 Applications of Evolutionary Computation.
 EvoApplications 2010.
 Lecture Notes in Computer Science, vol 6024.
 Springer, Berlin, Heidelberg, 2010.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ge_supermario"
literal "false"

\end_inset

N.
 Shaker, M.
 Nicolau, G.
 N.
 Yannakakis, J.
 Togelius, M.
 O'Neill, Evolving levels for Super Mario Bros using grammatical evolution,
 2012 IEEE Conference on Computational Intelligence and Games (CIG), 2012,
 pp.
 304-31.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ge_energy"
literal "false"

\end_inset

D.
 Martínez-Rodríguez, J.
 M.
 Colmenar, J.
 I.
 Hidalgo, R.J.
 Villanueva Micó, S.
 Salcedo-Sanz, Particle swarm grammatical evolution for energy demand estimation
, Energy Science and Engineering 
\series bold
8
\series default
, pp.
 1068-1079, 2020.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ge_crypt"
literal "false"

\end_inset

C.
 Ryan, M.
 Kshirsagar, G.
 Vaidya, G.
 et al.
 Design of a cryptographically secure pseudo random number generator with
 grammatical evolution.
 Sci Rep 
\series bold
12
\series default
, 8602, 2022.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ge_trading"
literal "false"

\end_inset

C.
 Martín, D.
 Quintana, P.
 Isasi, Grammatical Evolution-based ensembles for algorithmic trading, Applied
 Soft Computing 
\series bold
84
\series default
, 105713, 2019.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "nnt_bound"
literal "false"

\end_inset

Anastasopoulos, N., Tsoulos, I.G., Karvounis, E.
 et al.
 Locate the Bounding Box of Neural Networks with Intervals.
 Neural Process Lett 52, 2241–2251 (2020).
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(1989)"
key "uci"
literal "false"

\end_inset

 M.
 Kelly, R.
 Longjohn, K.
 Nottingham, The UCI Machine Learning Repository, https://archive.ics.uci.edu.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Keel"
literal "false"

\end_inset

J.
 Alcalá-Fdez, A.
 Fernandez, J.
 Luengo, J.
 Derrac, S.
 García, L.
 Sánchez, F.
 Herrera.
 KEEL Data-Mining Software Tool: Data Set Repository, Integration of Algorithms
 and Experimental Analysis Framework.
 Journal of Multiple-Valued Logic and Soft Computing 17, pp.
 255-287, 2011.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "appendicitis"
literal "false"

\end_inset

Weiss, Sholom M.
 and Kulikowski, Casimir A., Computer Systems That Learn: Classification
 and Prediction Methods from Statistics, Neural Nets, Machine Learning,
 and Expert Systems, Morgan Kaufmann Publishers Inc, 1991.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Tzimourta(2018)"
key "alcohol"
literal "false"

\end_inset

Tzimourta, K.D.; Tsoulos, I.; Bilero, I.T.; Tzallas, A.T.; Tsipouras, M.G.; Giannakeas,
 N.
 Direct Assessment of Alcohol Consumption in Mental State Using Brain Computer
 Interfaces and Grammatical Evolution.
 Inventions 2018, 3, 51.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "Quinlan(2018)"
key "australian"
literal "false"

\end_inset

J.R.
 Quinlan, Simplifying Decision Trees.
 International Journal of Man-Machine Studies 
\series bold
27
\series default
, pp.
 221-234, 1987.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "balance"
literal "false"

\end_inset

T.
 Shultz, D.
 Mareschal, W.
 Schmidt, Modeling Cognitive Development on Balance Scale Phenomena, Machine
 Learning 
\series bold
16
\series default
, pp.
 59-88, 1994.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2004)"
key "cleveland1"
literal "false"

\end_inset

Z.H.
 Zhou,Y.
 Jiang, NeC4.5: neural ensemble based C4.5," in IEEE Transactions on Knowledge
 and Data Engineering 
\series bold
16
\series default
, pp.
 770-773, 2004.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "cleveland2"
literal "false"

\end_inset

R.
 Setiono , W.K.
 Leow, FERNN: An Algorithm for Fast Extraction of Rules from Neural Networks,
 Applied Intelligence 
\series bold
12
\series default
, pp.
 15-25, 2000.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(1998)"
key "dermatology"
literal "false"

\end_inset

G.
 Demiroz, H.A.
 Govenir, N.
 Ilter, Learning Differential Diagnosis of Eryhemato-Squamous Diseases using
 Voting Feature Intervals, Artificial Intelligence in Medicine.
 
\series bold
13
\series default
, pp.
 147–165, 1998.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(1996)"
key "ecoli"
literal "false"

\end_inset

P.
 Horton, K.Nakai, A Probabilistic Classification System for Predicting the
 Cellular Localization Sites of Proteins, In: Proceedings of International
 Conference on Intelligent Systems for Molecular Biology 
\series bold
4
\series default
, pp.
 109-15, 1996.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(1977)"
key "hayes-roth"
literal "false"

\end_inset

B.
 Hayes-Roth, B., F.
 Hayes-Roth.
 Concept learning and the recognition and classification of exemplars.
 Journal of Verbal Learning and Verbal Behavior 
\series bold
16
\series default
, pp.
 321-338, 1977.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(1997)"
key "heart"
literal "false"

\end_inset

I.
 Kononenko, E.
 Šimec, M.
 Robnik-Šikonja, Overcoming the Myopia of Inductive Learning Algorithms
 with RELIEFF, Applied Intelligence 
\series bold
7
\series default
, pp.
 39–55, 1997
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2002)"
key "housevotes"
literal "false"

\end_inset

R.M.
 French, N.
 Chater, Using noise to compute error surfaces in connectionist networks:
 a novel means of reducing catastrophic forgetting, Neural Comput.
 
\series bold
14
\series default
, pp.
 1755-1769, 2002.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2004)"
key "ion1"
literal "false"

\end_inset

J.G.
 Dy , C.E.
 Brodley, Feature Selection for Unsupervised Learning, The Journal of Machine
 Learning Research 
\series bold
5
\series default
, pp 845–889, 2004.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ion2"
literal "false"

\end_inset

S.
 J.
 Perantonis, V.
 Virvilis, Input Feature Extraction for Multilayered Perceptrons Using Supervise
d Principal Component Analysis, Neural Processing Letters 
\series bold
10
\series default
, pp 243–252, 1999.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2002)"
key "liver"
literal "false"

\end_inset

 J.
 Garcke, M.
 Griebel, Classification with sparse grids using simplicial basis functions,
 Intell.
 Data Anal.
 
\series bold
6
\series default
, pp.
 483-502, 2002.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "liver1"
literal "false"

\end_inset

J.
 Mcdermott, R.S.
 Forsyth, Diagnosing a disorder in a classification benchmark, Pattern Recogniti
on Letters 
\series bold
73
\series default
, pp.
 41-43, 2016.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2002)"
key "lymography"
literal "false"

\end_inset

G.
 Cestnik, I.
 Konenenko, I.
 Bratko, Assistant-86: A Knowledge-Elicitation Tool for Sophisticated Users.
 In: Bratko, I.
 and Lavrac, N., Eds., Progress in Machine Learning, Sigma Press, Wilmslow,
 pp.
 31-45, 1987.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "mammographic"
literal "false"

\end_inset

M.
 Elter, R.
 Schulz-Wendtland, T.
 Wittenberg, The prediction of breast cancer biopsy outcomes using two CAD
 approaches that both emphasize an intelligible decision process, Med Phys.
 
\series bold
34
\series default
, pp.
 4164-72, 2007.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "parkinsons1"
literal "false"

\end_inset

M.A.
 Little, P.E.
 McSharry, S.J Roberts et al, Exploiting Nonlinear Recurrence and Fractal
 Scaling Properties for Voice Disorder Detection.
 BioMed Eng OnLine 
\series bold
6
\series default
, 23, 2007.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "parkinsons2"
literal "false"

\end_inset

M.A.
 Little, P.E.
 McSharry, E.J.
 Hunter, J.
 Spielman, L.O.
 Ramig, Suitability of dysphonia measurements for telemonitoring of Parkinson's
 disease.
 IEEE Trans Biomed Eng.
 
\series bold
56
\series default
, pp.
 1015-1022, 2009.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "pima"
literal "false"

\end_inset

J.W.
 Smith, J.E.
 Everhart, W.C.
 Dickson, W.C.
 Knowler, R.S.
 Johannes, Using the ADAP learning algorithm to forecast the onset of diabetes
 mellitus, In: Proceedings of the Symposium on Computer Applications and
 Medical Care IEEE Computer Society Press, pp.261-265, 1988.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "popfailures"
literal "false"

\end_inset

D.D.
 Lucas, R.
 Klein, J.
 Tannahill, D.
 Ivanova, S.
 Brandon, D.
 Domyancic, Y.
 Zhang, Failure analysis of parameter-induced simulation crashes in climate
 models, Geoscientific Model Development 
\series bold
6
\series default
, pp.
 1157-1171, 2013.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "regions2"
literal "false"

\end_inset

N.
 Giannakeas, M.G.
 Tsipouras, A.T.
 Tzallas, K.
 Kyriakidi, Z.E.
 Tsianou, P.
 Manousou, A.
 Hall, E.C.
 Karvounis, V.
 Tsianos, E.
 Tsianos, A clustering based method for collagen proportional area extraction
 in liver biopsy images (2015) Proceedings of the Annual International Conferenc
e of the IEEE Engineering in Medicine and Biology Society, EMBS, 2015-November,
 art.
 no.
 7319047, pp.
 3097-3100.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "saheart"
literal "false"

\end_inset

T.
 Hastie, R.
 Tibshirani, Non-parametric logistic and proportional odds regression, JRSS-C
 (Applied Statistics) 
\series bold
36
\series default
, pp.
 260–276, 1987.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "segment"
literal "false"

\end_inset

M.
 Dash, H.
 Liu, P.
 Scheuermann, K.
 L.
 Tan, Fast hierarchical clustering and its validation, Data & Knowledge
 Engineering 
\series bold
44
\series default
, pp 109–138, 2003.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "student"
literal "false"

\end_inset

P.
 Cortez, A.
 M.
 Gonçalves Silva, Using data mining to predict secondary school student
 performance, In Proceedings of 5th FUture BUsiness TEChnology Conference
 (FUBUTEC 2008) (pp.
 5–12).
 EUROSIS-ETI, 2008.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "transfusion"
literal "false"

\end_inset

I-Cheng Yeh, King-Jang Yang, Tao-Ming Ting, Knowledge discovery on RFM model
 using Bernoulli sequence, Expert Systems with Applications 
\series bold
36
\series default
, pp.
 5866-5871, 2009.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "wdbc1"
literal "false"

\end_inset

Jeyasingh, S., & Veluchamy, M.
 (2017).
 Modified bat algorithm for feature selection with the Wisconsin diagnosis
 breast cancer (WDBC) dataset.
 Asian Pacific journal of cancer prevention: APJCP, 18(5), 1257.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "wdbc2"
literal "false"

\end_inset

Alshayeji, M.
 H., Ellethy, H., & Gupta, R.
 (2022).
 Computer-aided detection of breast cancer on the Wisconsin dataset: An
 artificial neural networks approach.
 Biomedical signal processing and control, 71, 103141.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "wine1"
literal "false"

\end_inset

M.
 Raymer, T.E.
 Doom, L.A.
 Kuhn, W.F.
 Punch, Knowledge discovery in medical and biological datasets using a hybrid
 Bayes classifier/evolutionary algorithm.
 IEEE transactions on systems, man, and cybernetics.
 Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics
 Society, 
\series bold
33
\series default
 , pp.
 802-813, 2003.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "wine2"
literal "false"

\end_inset

P.
 Zhong, M.
 Fukushima, Regularized nonsmooth Newton method for multi-class support
 vector machines, Optimization Methods and Software 
\series bold
22
\series default
, pp.
 225-236, 2007.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "eeg1"
literal "false"

\end_inset

R.
 G.
 Andrzejak, K.
 Lehnertz, F.Mormann, C.
 Rieke, P.
 David, and C.
 E.
 Elger, “Indications of nonlinear deterministic and finite-dimensional structure
s in time series of brain electrical activity: dependence on recording region
 and brain state,” Physical Review E, vol.
 64, no.
 6, Article ID 061907, 8 pages, 2001.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "eeg2"
literal "true"

\end_inset

A.
 T.
 Tzallas, M.
 G.
 Tsipouras, and D.
 I.
 Fotiadis, “Automatic Seizure Detection Based on Time-Frequency Analysis
 and Artificial Neural Networks,” Computational Intelligence and Neuroscience,
 vol.
 2007, Article ID 80510, 13 pages, 2007.
 doi:10.1155/2007/80510
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "zoo"
literal "false"

\end_inset

M.
 Koivisto, K.
 Sood, Exact Bayesian Structure Discovery in Bayesian Networks, The Journal
 of Machine Learning Research
\series bold
 5
\series default
, pp.
 549–573, 2004.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "abalone"
literal "false"

\end_inset

Nash, W.J.; Sellers, T.L.; Talbot, S.R.; Cawthor, A.J.; Ford, W.B.
 The Population Biology of Abalone (_Haliotis_ species) in Tasmania.
 I.
 Blacklip Abalone (_H.
 rubra_) from the North Coast and Islands of Bass Strait, Sea Fisheries
 Division; Technical Report No.
 48; Department of Primary Industry and Fisheries, Tasmania: Hobart, Australia,
 1994; ISSN 1034-3288
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "airfoil"
literal "false"

\end_inset

Brooks, T.F.; Pope, D.S.; Marcolini, A.M.
 Airfoil Self-Noise and Prediction.
 Technical Report, NASA RP-1218.
 July 1989.
 Available online: https://ntrs.nasa.gov/citations/19890016302 (accessed on
 14 November 2024).
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "concrete"
literal "false"

\end_inset

I.Cheng Yeh, Modeling of strength of high performance concrete using artificial
 neural networks, Cement and Concrete Research.
 
\series bold
28
\series default
, pp.
 1797-1808, 1998.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "friedman"
literal "false"

\end_inset

Friedman, J.
 (1991): Multivariate Adaptative Regression Splines.
 Annals of Statistics, 19:1, 1--141.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
label "(2007)"
key "housing"
literal "false"

\end_inset

D.
 Harrison and D.L.
 Rubinfeld, Hedonic prices and the demand for clean ai, J.
 Environ.
 Economics & Management 
\series bold
5
\series default
, pp.
 81-102, 1978.
\end_layout

\begin_layout End Whole Page
\begin_inset Note Note
status open

\begin_layout Plain Layout
Keep empty!
\end_layout

\end_inset


\end_layout

\end_body
\end_document
