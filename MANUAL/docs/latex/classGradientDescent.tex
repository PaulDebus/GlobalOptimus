\hypertarget{classGradientDescent}{}\doxysection{Gradient\+Descent Class Reference}
\label{classGradientDescent}\index{GradientDescent@{GradientDescent}}


The \mbox{\hyperlink{classGradientDescent}{Gradient\+Descent}} class implements the gradient descent local optimizer.  




{\ttfamily \#include $<$gradientdescent.\+h$>$}



Inheritance diagram for Gradient\+Descent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=170pt]{classGradientDescent__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for Gradient\+Descent\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classGradientDescent__coll__graph}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classGradientDescent_af787a86a99226e78c829bc315cffd546}\label{classGradientDescent_af787a86a99226e78c829bc315cffd546}} 
{\bfseries Gradient\+Descent} ()
\begin{DoxyCompactList}\small\item\em \mbox{\hyperlink{classGradientDescent}{Gradient\+Descent}} The constructor of the class. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classGradientDescent_a473c945774babcb838505d3ab76008e6}{init}} ()
\begin{DoxyCompactList}\small\item\em init Initializes the parameters of the method. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classGradientDescent_a9b29de8013f85b9b04601b5bbaa610f2}{step}} ()
\begin{DoxyCompactList}\small\item\em step Performs a step of the optimizer. \end{DoxyCompactList}\item 
virtual bool \mbox{\hyperlink{classGradientDescent_a3de64b31e29f2fefb2f7c772dd696826}{terminated}} ()
\begin{DoxyCompactList}\small\item\em terminated \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classGradientDescent_aa27f166ae7a0ca172769a8b17d86278c}\label{classGradientDescent_aa27f166ae7a0ca172769a8b17d86278c}} 
void {\bfseries updaterate} ()
\begin{DoxyCompactList}\small\item\em updaterate Updates the search rate. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classGradientDescent_a073e92fe6d123d77d835a13ab4e10b26}\label{classGradientDescent_a073e92fe6d123d77d835a13ab4e10b26}} 
void {\bfseries updatepoint} ()
\begin{DoxyCompactList}\small\item\em updatepoint Updates the current point. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classGradientDescent_aae3e53d42f9664861eaeaed85cd57041}{show\+Debug}} ()
\begin{DoxyCompactList}\small\item\em show\+Debug Displays debug information. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{classGradientDescent_a3587d878aa1fbc45d11b42e93853cf38}{set\+Point}} (Data \&x, double \&y)
\begin{DoxyCompactList}\small\item\em set\+Point Sets the initial point. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{classGradientDescent_a0255c51897313be6abc77c5d50b4e407}{get\+Point}} (Data \&x, double \&y)
\begin{DoxyCompactList}\small\item\em get\+Point Returns the located local minimum. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classGradientDescent_a48aa524182591eceaaa27c70a8c6332a}\label{classGradientDescent_a48aa524182591eceaaa27c70a8c6332a}} 
int {\bfseries maxiters}
\item 
\mbox{\Hypertarget{classGradientDescent_aacbc2e4a56e73ac9db85ad31905f55f8}\label{classGradientDescent_aacbc2e4a56e73ac9db85ad31905f55f8}} 
int {\bfseries iteration}
\item 
\mbox{\Hypertarget{classGradientDescent_ac0fab839847e6572b9b97ea36b847d7a}\label{classGradientDescent_ac0fab839847e6572b9b97ea36b847d7a}} 
double {\bfseries eps}
\item 
\mbox{\Hypertarget{classGradientDescent_ab140131dec29fde79a707c4048f9185b}\label{classGradientDescent_ab140131dec29fde79a707c4048f9185b}} 
double {\bfseries rate}
\item 
\mbox{\Hypertarget{classGradientDescent_ae204a9e9258f08f08e44e1623eaa0e6a}\label{classGradientDescent_ae204a9e9258f08f08e44e1623eaa0e6a}} 
Data {\bfseries xpoint}
\item 
\mbox{\Hypertarget{classGradientDescent_a574133d5e2e220db8749eeb31b2309bf}\label{classGradientDescent_a574133d5e2e220db8749eeb31b2309bf}} 
double {\bfseries ypoint}
\item 
\mbox{\Hypertarget{classGradientDescent_a358036813737703291c2763472a56c65}\label{classGradientDescent_a358036813737703291c2763472a56c65}} 
bool {\bfseries has\+Initialized}
\item 
\mbox{\Hypertarget{classGradientDescent_a4a5f2a577532babdaea8c7b51c179fd3}\label{classGradientDescent_a4a5f2a577532babdaea8c7b51c179fd3}} 
\mbox{\hyperlink{classLineSearch}{Line\+Search}} $\ast$ {\bfseries lt}
\item 
\mbox{\Hypertarget{classGradientDescent_a2aed0824e06c45e4217072fd3c710851}\label{classGradientDescent_a2aed0824e06c45e4217072fd3c710851}} 
QString {\bfseries line\+Search\+Method}
\end{DoxyCompactItemize}
\doxysubsection*{Additional Inherited Members}


\doxysubsection{Detailed Description}
The \mbox{\hyperlink{classGradientDescent}{Gradient\+Descent}} class implements the gradient descent local optimizer. 

\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{classGradientDescent_a0255c51897313be6abc77c5d50b4e407}\label{classGradientDescent_a0255c51897313be6abc77c5d50b4e407}} 
\index{GradientDescent@{GradientDescent}!getPoint@{getPoint}}
\index{getPoint@{getPoint}!GradientDescent@{GradientDescent}}
\doxysubsubsection{\texorpdfstring{getPoint()}{getPoint()}}
{\footnotesize\ttfamily void Gradient\+Descent\+::get\+Point (\begin{DoxyParamCaption}\item[{Data \&}]{x,  }\item[{double \&}]{y }\end{DoxyParamCaption})}



get\+Point Returns the located local minimum. 


\begin{DoxyParams}{Parameters}
{\em x} & \\
\hline
{\em y} & \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classGradientDescent_a473c945774babcb838505d3ab76008e6}\label{classGradientDescent_a473c945774babcb838505d3ab76008e6}} 
\index{GradientDescent@{GradientDescent}!init@{init}}
\index{init@{init}!GradientDescent@{GradientDescent}}
\doxysubsubsection{\texorpdfstring{init()}{init()}}
{\footnotesize\ttfamily void Gradient\+Descent\+::init (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



init Initializes the parameters of the method. 



Reimplemented from \mbox{\hyperlink{classOptimizer_a27fb9a8463a57b0a010f98053686e818}{Optimizer}}.

\mbox{\Hypertarget{classGradientDescent_a3587d878aa1fbc45d11b42e93853cf38}\label{classGradientDescent_a3587d878aa1fbc45d11b42e93853cf38}} 
\index{GradientDescent@{GradientDescent}!setPoint@{setPoint}}
\index{setPoint@{setPoint}!GradientDescent@{GradientDescent}}
\doxysubsubsection{\texorpdfstring{setPoint()}{setPoint()}}
{\footnotesize\ttfamily void Gradient\+Descent\+::set\+Point (\begin{DoxyParamCaption}\item[{Data \&}]{x,  }\item[{double \&}]{y }\end{DoxyParamCaption})}



set\+Point Sets the initial point. 


\begin{DoxyParams}{Parameters}
{\em x} & \\
\hline
{\em y} & \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classGradientDescent_aae3e53d42f9664861eaeaed85cd57041}\label{classGradientDescent_aae3e53d42f9664861eaeaed85cd57041}} 
\index{GradientDescent@{GradientDescent}!showDebug@{showDebug}}
\index{showDebug@{showDebug}!GradientDescent@{GradientDescent}}
\doxysubsubsection{\texorpdfstring{showDebug()}{showDebug()}}
{\footnotesize\ttfamily void Gradient\+Descent\+::show\+Debug (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



show\+Debug Displays debug information. 



Reimplemented from \mbox{\hyperlink{classOptimizer_a099eb0b407a92de4c83ba2ee7aa638ce}{Optimizer}}.

\mbox{\Hypertarget{classGradientDescent_a9b29de8013f85b9b04601b5bbaa610f2}\label{classGradientDescent_a9b29de8013f85b9b04601b5bbaa610f2}} 
\index{GradientDescent@{GradientDescent}!step@{step}}
\index{step@{step}!GradientDescent@{GradientDescent}}
\doxysubsubsection{\texorpdfstring{step()}{step()}}
{\footnotesize\ttfamily void Gradient\+Descent\+::step (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



step Performs a step of the optimizer. 



Reimplemented from \mbox{\hyperlink{classOptimizer_a2b3ee87deb4b5218adfece7ecaad5cb1}{Optimizer}}.

\mbox{\Hypertarget{classGradientDescent_a3de64b31e29f2fefb2f7c772dd696826}\label{classGradientDescent_a3de64b31e29f2fefb2f7c772dd696826}} 
\index{GradientDescent@{GradientDescent}!terminated@{terminated}}
\index{terminated@{terminated}!GradientDescent@{GradientDescent}}
\doxysubsubsection{\texorpdfstring{terminated()}{terminated()}}
{\footnotesize\ttfamily bool Gradient\+Descent\+::terminated (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



terminated 

\begin{DoxyReturn}{Returns}
true when the optimizer should be finished. 
\end{DoxyReturn}


Reimplemented from \mbox{\hyperlink{classOptimizer_a52c02dc16fbc45201ab64a1c542dea41}{Optimizer}}.

