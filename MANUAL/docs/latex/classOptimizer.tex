\hypertarget{classOptimizer}{}\doxysection{Optimizer Class Reference}
\label{classOptimizer}\index{Optimizer@{Optimizer}}


The \mbox{\hyperlink{classOptimizer}{Optimizer}} class implements a general class for optimization methods.  




{\ttfamily \#include $<$optimizer.\+h$>$}



Inheritance diagram for Optimizer\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[height=550pt]{classOptimizer__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for Optimizer\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classOptimizer__coll__graph}
\end{center}
\end{figure}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classOptimizer_a95e6c40a55223f6b1e04194733a2b9a7}\label{classOptimizer_a95e6c40a55223f6b1e04194733a2b9a7}} 
{\bfseries Optimizer} ()
\begin{DoxyCompactList}\small\item\em \mbox{\hyperlink{classOptimizer}{Optimizer}} the constructor of the class. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{classOptimizer_a4873f5cd8771752d4672815b549712af}{set\+Method\+Logger}} (\mbox{\hyperlink{classLogger}{Logger}} $\ast$p)
\begin{DoxyCompactList}\small\item\em set\+Method\+Logger, changes the logger method \end{DoxyCompactList}\item 
\mbox{\hyperlink{classLogger}{Logger}} $\ast$ \mbox{\hyperlink{classOptimizer_a57ce86bd56d85cfcfa471bdccc73622d}{get\+Method\+Logger}} ()
\begin{DoxyCompactList}\small\item\em get\+Method\+Logger \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classOptimizer_a099eb0b407a92de4c83ba2ee7aa638ce}{show\+Debug}} ()
\begin{DoxyCompactList}\small\item\em show\+Debug, executed when a log message should be displayed \end{DoxyCompactList}\item 
void \mbox{\hyperlink{classOptimizer_aa56a5681b25a357e918deb8c9c6557d0}{set\+Problem}} (\mbox{\hyperlink{classProblem}{Problem}} $\ast$p)
\begin{DoxyCompactList}\small\item\em set\+Problem, changes the objective problem to p \end{DoxyCompactList}\item 
void \mbox{\hyperlink{classOptimizer_ab25bf113840e69f2d96f33651fe4cea5}{add\+Param}} (\mbox{\hyperlink{classParameter}{Parameter}} p)
\begin{DoxyCompactList}\small\item\em add\+Param adds a new parameter \end{DoxyCompactList}\item 
void \mbox{\hyperlink{classOptimizer_af491c950b6887acea94ac74ba9b546a6}{set\+Param}} (QString name, QString value, QString help=\char`\"{}\char`\"{})
\begin{DoxyCompactList}\small\item\em set\+Param adds a new parameter \end{DoxyCompactList}\item 
\mbox{\hyperlink{classParameter}{Parameter}} \mbox{\hyperlink{classOptimizer_a6dd88965bee285839ba05c3b978e433c}{get\+Param}} (QString name)
\begin{DoxyCompactList}\small\item\em get\+Param \end{DoxyCompactList}\item 
QJson\+Object \mbox{\hyperlink{classOptimizer_a3e84a62e969af5fce69dca8640e6bdfc}{get\+Params}} ()
\begin{DoxyCompactList}\small\item\em get\+Params \end{DoxyCompactList}\item 
void \mbox{\hyperlink{classOptimizer_ae028741148a2bff3313c558ffc4eaef2}{set\+Params}} (QJson\+Object \&x)
\begin{DoxyCompactList}\small\item\em set\+Params changes the parameters \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classOptimizer_a27fb9a8463a57b0a010f98053686e818}{init}} ()
\begin{DoxyCompactList}\small\item\em init, executed before the method starts \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classOptimizer_a2b3ee87deb4b5218adfece7ecaad5cb1}{step}} ()
\begin{DoxyCompactList}\small\item\em step, the step of the optimizer \end{DoxyCompactList}\item 
virtual bool \mbox{\hyperlink{classOptimizer_a52c02dc16fbc45201ab64a1c542dea41}{terminated}} ()
\begin{DoxyCompactList}\small\item\em terminated \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classOptimizer_a7c39b0295483903664766a9f37258c6a}\label{classOptimizer_a7c39b0295483903664766a9f37258c6a}} 
virtual void {\bfseries solve} ()
\begin{DoxyCompactList}\small\item\em solve the main execution function of the optimizer \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classOptimizer_a591ee9a182056d9d6bda5206ca952d77}{done}} ()
\begin{DoxyCompactList}\small\item\em done, executed when the method terminates \end{DoxyCompactList}\item 
double \mbox{\hyperlink{classOptimizer_a849f581584a16450089437f0374c357d}{local\+Search}} (Data \&x)
\begin{DoxyCompactList}\small\item\em local\+Search \end{DoxyCompactList}\item 
\mbox{\hyperlink{classProblem}{Problem}} $\ast$ \mbox{\hyperlink{classOptimizer_a7b70e8c55db0ff15b404ba97a75681b5}{get\+Problem}} ()
\begin{DoxyCompactList}\small\item\em get\+Problem \end{DoxyCompactList}\item 
QString\+List \mbox{\hyperlink{classOptimizer_ab1918a23188763780a18b85c89e0a4e5}{get\+Parameter\+Names}} () const
\begin{DoxyCompactList}\small\item\em get\+Parameter\+Names \end{DoxyCompactList}\item 
void \mbox{\hyperlink{classOptimizer_adcabe7fa24cc4c71c0acdfd3f7312254}{sample\+From\+Problem}} (int \&N, Matrix \&xsample, Data \&ysample)
\begin{DoxyCompactList}\small\item\em sample\+From\+Problem, samples from the objective function a series of samples. \end{DoxyCompactList}\item 
QString \mbox{\hyperlink{classOptimizer_adba390480609f5755376c4e6d2899b6c}{get\+Termination\+Method}} () const
\begin{DoxyCompactList}\small\item\em get\+Termination\+Method \end{DoxyCompactList}\item 
\mbox{\hyperlink{classParameterList}{Parameter\+List}} \mbox{\hyperlink{classOptimizer_a7a67c7fadaca273cad87f5162ac8d48a}{get\+Parameter\+List}} ()
\begin{DoxyCompactList}\small\item\em get\+Parameter\+List \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classOptimizer_a8076c8c4258421ebb29c218a71e252e5}\label{classOptimizer_a8076c8c4258421ebb29c218a71e252e5}} 
\mbox{\hyperlink{classParameterList}{Parameter\+List}} {\bfseries param\+List}
\begin{DoxyCompactList}\small\item\em param\+List the list of parameters \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classOptimizer_a880309f7764aa8bc03b8f7f2bdd4e7ed}\label{classOptimizer_a880309f7764aa8bc03b8f7f2bdd4e7ed}} 
\mbox{\hyperlink{classProblem}{Problem}} $\ast$ {\bfseries my\+Problem}
\begin{DoxyCompactList}\small\item\em my\+Problem the objective problem \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classOptimizer_aa64800e645a9e305ee52d3274c669098}\label{classOptimizer_aa64800e645a9e305ee52d3274c669098}} 
\mbox{\hyperlink{classDoubleBox}{Double\+Box}} {\bfseries double\+Box}
\begin{DoxyCompactList}\small\item\em double\+Box the \mbox{\hyperlink{classDoubleBox}{Double\+Box}} termination rule \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classOptimizer_a218e55b3cb475005a92e9902bc88ddf8}\label{classOptimizer_a218e55b3cb475005a92e9902bc88ddf8}} 
\mbox{\hyperlink{classSimilarity}{Similarity}} {\bfseries similarity}
\begin{DoxyCompactList}\small\item\em similarity the similarity termination rule \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classOptimizer_a652e3e2d73e3694a8004951f16741804}\label{classOptimizer_a652e3e2d73e3694a8004951f16741804}} 
\mbox{\hyperlink{classMean}{Mean}} {\bfseries mean}
\begin{DoxyCompactList}\small\item\em mean the mean\+Fitness termination rule \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classOptimizer_a17dd6ad2d8bedea974b13679d68edda3}\label{classOptimizer_a17dd6ad2d8bedea974b13679d68edda3}} 
\mbox{\hyperlink{classProblemSampler}{Problem\+Sampler}} $\ast$ {\bfseries problem\+Sampler}
\begin{DoxyCompactList}\small\item\em problem\+Sampler the sample used in most optimization methods \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classOptimizer_a8835fbda0e4bb157c436a14f8f467348}\label{classOptimizer_a8835fbda0e4bb157c436a14f8f467348}} 
QString {\bfseries termination\+Method}
\begin{DoxyCompactList}\small\item\em termination\+Method the used termination rule \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classOptimizer_a7bcc9a1b5d00792020ec199939e670e0}\label{classOptimizer_a7bcc9a1b5d00792020ec199939e670e0}} 
\mbox{\hyperlink{classLogger}{Logger}} $\ast$ {\bfseries method\+Logger}
\begin{DoxyCompactList}\small\item\em method\+Logger the use logging class \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
The \mbox{\hyperlink{classOptimizer}{Optimizer}} class implements a general class for optimization methods. 

\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{classOptimizer_ab25bf113840e69f2d96f33651fe4cea5}\label{classOptimizer_ab25bf113840e69f2d96f33651fe4cea5}} 
\index{Optimizer@{Optimizer}!addParam@{addParam}}
\index{addParam@{addParam}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{addParam()}{addParam()}}
{\footnotesize\ttfamily void Optimizer\+::add\+Param (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{classParameter}{Parameter}}}]{p }\end{DoxyParamCaption})}



add\+Param adds a new parameter 


\begin{DoxyParams}{Parameters}
{\em p} & \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classOptimizer_a591ee9a182056d9d6bda5206ca952d77}\label{classOptimizer_a591ee9a182056d9d6bda5206ca952d77}} 
\index{Optimizer@{Optimizer}!done@{done}}
\index{done@{done}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{done()}{done()}}
{\footnotesize\ttfamily void Optimizer\+::done (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



done, executed when the method terminates 



Reimplemented in \mbox{\hyperlink{classACOP_a86a35efe2863f44945f7514045bda505}{ACOP}}, \mbox{\hyperlink{classArmadillo1_a692a9206ab253a592f846f8eedb2c744}{Armadillo1}}, \mbox{\hyperlink{classDifferentialEvolution_a0d8b8a54c5d755b550e25edf68209fd3}{Differential\+Evolution}}, \mbox{\hyperlink{classEGO_a4b9a66e6ed3dc0f9e477239809a0e0e7}{EGO}}, \mbox{\hyperlink{classGenetic_ade9c7be731805fae16bbb75b65bce580}{Genetic}}, \mbox{\hyperlink{classGWOoptimizer_a0d4e50a54e7ae51c661330716f6ba724}{GWOoptimizer}}, \mbox{\hyperlink{classHybridMethod_a6479ea26db08999277036c4a06ee15f7}{Hybrid\+Method}}, \mbox{\hyperlink{classiPso_ae358e7b754af5e883a944e96d75ee67b}{i\+Pso}}, \mbox{\hyperlink{classjDElsgo_ad35aad6a2006a11dc4dbc3d68ab62fd6}{j\+DElsgo}}, \mbox{\hyperlink{classMEWOA_a302555f2fd6163503f72826b20f76525}{MEWOA}}, \mbox{\hyperlink{classMultistart_a21f64e9db9bb14529f547a50b04843c8}{Multistart}}, \mbox{\hyperlink{classNelderMead_a4ecfa01e82c947d16aedb3dea0ca05a2}{Nelder\+Mead}}, \mbox{\hyperlink{classNeuralMinimizer_a182e1c61d6a134d2ee40fb1e1821c16b}{Neural\+Minimizer}}, \mbox{\hyperlink{classOFAlgorithm_a46e1b87cf712b2947fb24c40f4635a15}{OFAlgorithm}}, \mbox{\hyperlink{classParallelDe_ae3bee8c06cd71c8e8c14d1712bdcef2d}{Parallel\+De}}, \mbox{\hyperlink{classParallelPso_a47fcde7638b8c9e05eece921660d3edb}{Parallel\+Pso}}, \mbox{\hyperlink{classSAOP_a4645689a97f0a409099ed0b8e22c6605}{SAOP}}, \mbox{\hyperlink{classSimanMethod_a58ec48800839765b1d6106b7813b7a9c}{Siman\+Method}}, \mbox{\hyperlink{classUserMethod_af6444e7b87f9e967575abe58ed3237ae}{User\+Method}}, and \mbox{\hyperlink{classWOA_aa85539191e29b755d5bbd58e2765e733}{WOA}}.

\mbox{\Hypertarget{classOptimizer_a57ce86bd56d85cfcfa471bdccc73622d}\label{classOptimizer_a57ce86bd56d85cfcfa471bdccc73622d}} 
\index{Optimizer@{Optimizer}!getMethodLogger@{getMethodLogger}}
\index{getMethodLogger@{getMethodLogger}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{getMethodLogger()}{getMethodLogger()}}
{\footnotesize\ttfamily \mbox{\hyperlink{classLogger}{Logger}} $\ast$ Optimizer\+::get\+Method\+Logger (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



get\+Method\+Logger 

\begin{DoxyReturn}{Returns}
the used logger 
\end{DoxyReturn}
\mbox{\Hypertarget{classOptimizer_a6dd88965bee285839ba05c3b978e433c}\label{classOptimizer_a6dd88965bee285839ba05c3b978e433c}} 
\index{Optimizer@{Optimizer}!getParam@{getParam}}
\index{getParam@{getParam}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{getParam()}{getParam()}}
{\footnotesize\ttfamily \mbox{\hyperlink{classParameter}{Parameter}} Optimizer\+::get\+Param (\begin{DoxyParamCaption}\item[{QString}]{name }\end{DoxyParamCaption})}



get\+Param 


\begin{DoxyParams}{Parameters}
{\em name} & \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
alter the parameter 
\end{DoxyReturn}
\mbox{\Hypertarget{classOptimizer_a7a67c7fadaca273cad87f5162ac8d48a}\label{classOptimizer_a7a67c7fadaca273cad87f5162ac8d48a}} 
\index{Optimizer@{Optimizer}!getParameterList@{getParameterList}}
\index{getParameterList@{getParameterList}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{getParameterList()}{getParameterList()}}
{\footnotesize\ttfamily \mbox{\hyperlink{classParameterList}{Parameter\+List}} Optimizer\+::get\+Parameter\+List (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



get\+Parameter\+List 

\begin{DoxyReturn}{Returns}

\end{DoxyReturn}
\mbox{\Hypertarget{classOptimizer_ab1918a23188763780a18b85c89e0a4e5}\label{classOptimizer_ab1918a23188763780a18b85c89e0a4e5}} 
\index{Optimizer@{Optimizer}!getParameterNames@{getParameterNames}}
\index{getParameterNames@{getParameterNames}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{getParameterNames()}{getParameterNames()}}
{\footnotesize\ttfamily QString\+List Optimizer\+::get\+Parameter\+Names (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const}



get\+Parameter\+Names 

\begin{DoxyReturn}{Returns}
the list of the parameter names 
\end{DoxyReturn}
\mbox{\Hypertarget{classOptimizer_a3e84a62e969af5fce69dca8640e6bdfc}\label{classOptimizer_a3e84a62e969af5fce69dca8640e6bdfc}} 
\index{Optimizer@{Optimizer}!getParams@{getParams}}
\index{getParams@{getParams}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{getParams()}{getParams()}}
{\footnotesize\ttfamily QJson\+Object Optimizer\+::get\+Params (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



get\+Params 

\begin{DoxyReturn}{Returns}
the parameters in json format 
\end{DoxyReturn}
\mbox{\Hypertarget{classOptimizer_a7b70e8c55db0ff15b404ba97a75681b5}\label{classOptimizer_a7b70e8c55db0ff15b404ba97a75681b5}} 
\index{Optimizer@{Optimizer}!getProblem@{getProblem}}
\index{getProblem@{getProblem}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{getProblem()}{getProblem()}}
{\footnotesize\ttfamily \mbox{\hyperlink{classProblem}{Problem}} $\ast$ Optimizer\+::get\+Problem (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



get\+Problem 

\begin{DoxyReturn}{Returns}
a pointer to the objective problem 
\end{DoxyReturn}
\mbox{\Hypertarget{classOptimizer_adba390480609f5755376c4e6d2899b6c}\label{classOptimizer_adba390480609f5755376c4e6d2899b6c}} 
\index{Optimizer@{Optimizer}!getTerminationMethod@{getTerminationMethod}}
\index{getTerminationMethod@{getTerminationMethod}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{getTerminationMethod()}{getTerminationMethod()}}
{\footnotesize\ttfamily QString Optimizer\+::get\+Termination\+Method (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const}



get\+Termination\+Method 

\begin{DoxyReturn}{Returns}
the termination method in string format 
\end{DoxyReturn}
\mbox{\Hypertarget{classOptimizer_a27fb9a8463a57b0a010f98053686e818}\label{classOptimizer_a27fb9a8463a57b0a010f98053686e818}} 
\index{Optimizer@{Optimizer}!init@{init}}
\index{init@{init}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{init()}{init()}}
{\footnotesize\ttfamily void Optimizer\+::init (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



init, executed before the method starts 



Reimplemented in \mbox{\hyperlink{classACOP_ac6af193de13a06a14dcd57a853ec6cb1}{ACOP}}, \mbox{\hyperlink{classAdam_a435e16595b4c7d933034f4dbdc4d29ba}{Adam}}, \mbox{\hyperlink{classArmadillo1_ac9d6f989a8dce3349192ca81de52598b}{Armadillo1}}, \mbox{\hyperlink{classBfgs_af52050526827f0ac5902059a11def359}{Bfgs}}, \mbox{\hyperlink{classDifferentialEvolution_a64a9ca5c9f4d3bb4d68f504b8444ae45}{Differential\+Evolution}}, \mbox{\hyperlink{classEGO_a9d30cb18103cc638869743e8bc658f33}{EGO}}, \mbox{\hyperlink{classGenetic_a877bf84573faf86e915132f4413c2a83}{Genetic}}, \mbox{\hyperlink{classGradientDescent_a473c945774babcb838505d3ab76008e6}{Gradient\+Descent}}, \mbox{\hyperlink{classGWOoptimizer_a3debb6fcb37d158010e1695ece3fb928}{GWOoptimizer}}, \mbox{\hyperlink{classHybridMethod_a86618b0c7962addea01a4089eaf54c06}{Hybrid\+Method}}, \mbox{\hyperlink{classiPso_ac631c22e4c6fab1fe2807a1707068f89}{i\+Pso}}, \mbox{\hyperlink{classjDElsgo_aa3b639c87efedfc5b670f425b5de9430}{j\+DElsgo}}, \mbox{\hyperlink{classLbfgs_a0addb763f9ebbd5298190d8b03e0b6b1}{Lbfgs}}, \mbox{\hyperlink{classMEWOA_a8802cf48475e478bab4ef278781e5e15}{MEWOA}}, \mbox{\hyperlink{classMultistart_ae0a875186b49dc94ba6d2e714cbe79e0}{Multistart}}, \mbox{\hyperlink{classNelderMead_ac73c05b974efa36eba3a19fc6e8c3d5d}{Nelder\+Mead}}, \mbox{\hyperlink{classNeuralMinimizer_aa12dc37c2d28b393f14fe46223d20069}{Neural\+Minimizer}}, \mbox{\hyperlink{classOFAlgorithm_abb00d88bb18af72d7885f0b2a967ba72}{OFAlgorithm}}, \mbox{\hyperlink{classParallelDe_a72ad749228d44d6f519ba2c9e26d5e8f}{Parallel\+De}}, \mbox{\hyperlink{classParallelPso_ac664a47ff275ff0608d16f33e2679b02}{Parallel\+Pso}}, \mbox{\hyperlink{classSAOP_a676cd84209d5481876d2e716f7d32440}{SAOP}}, \mbox{\hyperlink{classSimanMethod_af46ad249c14e43cd77423aadd8246cab}{Siman\+Method}}, \mbox{\hyperlink{classUserMethod_a043891687cdbb4b1c98e6d262f2634c8}{User\+Method}}, and \mbox{\hyperlink{classWOA_a5fbf17ebaf50fd2b870df132a745b469}{WOA}}.

\mbox{\Hypertarget{classOptimizer_a849f581584a16450089437f0374c357d}\label{classOptimizer_a849f581584a16450089437f0374c357d}} 
\index{Optimizer@{Optimizer}!localSearch@{localSearch}}
\index{localSearch@{localSearch}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{localSearch()}{localSearch()}}
{\footnotesize\ttfamily double Optimizer\+::local\+Search (\begin{DoxyParamCaption}\item[{Data \&}]{x }\end{DoxyParamCaption})}



local\+Search 


\begin{DoxyParams}{Parameters}
{\em x} & \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
a new point obtained by the usage of the prefered local search method. 
\end{DoxyReturn}
\mbox{\Hypertarget{classOptimizer_adcabe7fa24cc4c71c0acdfd3f7312254}\label{classOptimizer_adcabe7fa24cc4c71c0acdfd3f7312254}} 
\index{Optimizer@{Optimizer}!sampleFromProblem@{sampleFromProblem}}
\index{sampleFromProblem@{sampleFromProblem}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{sampleFromProblem()}{sampleFromProblem()}}
{\footnotesize\ttfamily void Optimizer\+::sample\+From\+Problem (\begin{DoxyParamCaption}\item[{int \&}]{N,  }\item[{Matrix \&}]{xsample,  }\item[{Data \&}]{ysample }\end{DoxyParamCaption})}



sample\+From\+Problem, samples from the objective function a series of samples. 


\begin{DoxyParams}{Parameters}
{\em N,the} & number of samples. \\
\hline
{\em xsample,the} & vector holding the samples. \\
\hline
{\em ysample,the} & function values of the samples. \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classOptimizer_a4873f5cd8771752d4672815b549712af}\label{classOptimizer_a4873f5cd8771752d4672815b549712af}} 
\index{Optimizer@{Optimizer}!setMethodLogger@{setMethodLogger}}
\index{setMethodLogger@{setMethodLogger}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{setMethodLogger()}{setMethodLogger()}}
{\footnotesize\ttfamily void Optimizer\+::set\+Method\+Logger (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{classLogger}{Logger}} $\ast$}]{p }\end{DoxyParamCaption})}



set\+Method\+Logger, changes the logger method 


\begin{DoxyParams}{Parameters}
{\em p} & \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classOptimizer_af491c950b6887acea94ac74ba9b546a6}\label{classOptimizer_af491c950b6887acea94ac74ba9b546a6}} 
\index{Optimizer@{Optimizer}!setParam@{setParam}}
\index{setParam@{setParam}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{setParam()}{setParam()}}
{\footnotesize\ttfamily void Optimizer\+::set\+Param (\begin{DoxyParamCaption}\item[{QString}]{name,  }\item[{QString}]{value,  }\item[{QString}]{help = {\ttfamily \char`\"{}\char`\"{}} }\end{DoxyParamCaption})}



set\+Param adds a new parameter 


\begin{DoxyParams}{Parameters}
{\em name} & \\
\hline
{\em value} & \\
\hline
{\em help} & \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classOptimizer_ae028741148a2bff3313c558ffc4eaef2}\label{classOptimizer_ae028741148a2bff3313c558ffc4eaef2}} 
\index{Optimizer@{Optimizer}!setParams@{setParams}}
\index{setParams@{setParams}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{setParams()}{setParams()}}
{\footnotesize\ttfamily void Optimizer\+::set\+Params (\begin{DoxyParamCaption}\item[{QJson\+Object \&}]{x }\end{DoxyParamCaption})}



set\+Params changes the parameters 


\begin{DoxyParams}{Parameters}
{\em x} & \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classOptimizer_aa56a5681b25a357e918deb8c9c6557d0}\label{classOptimizer_aa56a5681b25a357e918deb8c9c6557d0}} 
\index{Optimizer@{Optimizer}!setProblem@{setProblem}}
\index{setProblem@{setProblem}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{setProblem()}{setProblem()}}
{\footnotesize\ttfamily void Optimizer\+::set\+Problem (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{classProblem}{Problem}} $\ast$}]{p }\end{DoxyParamCaption})}



set\+Problem, changes the objective problem to p 


\begin{DoxyParams}{Parameters}
{\em p} & \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classOptimizer_a099eb0b407a92de4c83ba2ee7aa638ce}\label{classOptimizer_a099eb0b407a92de4c83ba2ee7aa638ce}} 
\index{Optimizer@{Optimizer}!showDebug@{showDebug}}
\index{showDebug@{showDebug}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{showDebug()}{showDebug()}}
{\footnotesize\ttfamily void Optimizer\+::show\+Debug (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



show\+Debug, executed when a log message should be displayed 



Reimplemented in \mbox{\hyperlink{classACOP_abe1787c7aac3679ce7f9ff09daa1fcbb}{ACOP}}, \mbox{\hyperlink{classArmadillo1_a0a16656ae97ffb191d543af1f0130e7a}{Armadillo1}}, \mbox{\hyperlink{classDifferentialEvolution_ac3a823b03e005cbd77bcbd1fb9a94a7a}{Differential\+Evolution}}, \mbox{\hyperlink{classGenetic_a2e7752fad5501e0f74c2c28ccb2a21a6}{Genetic}}, \mbox{\hyperlink{classGradientDescent_aae3e53d42f9664861eaeaed85cd57041}{Gradient\+Descent}}, \mbox{\hyperlink{classGWOoptimizer_a38bab3fa130addf07063db862e7af9f8}{GWOoptimizer}}, \mbox{\hyperlink{classHybridMethod_a8c9f01ef4d24f6b976add36f0a77da47}{Hybrid\+Method}}, \mbox{\hyperlink{classiPso_af69469bee12d54ed3b587959605aa724}{i\+Pso}}, \mbox{\hyperlink{classjDElsgo_a4533646c1863d1c3f923985fec986672}{j\+DElsgo}}, \mbox{\hyperlink{classMEWOA_ae68fd5f499ff9e8a70adfc16ad57b17f}{MEWOA}}, \mbox{\hyperlink{classMultistart_af83c6e3e9b064f493a0e5e805090ee3d}{Multistart}}, \mbox{\hyperlink{classNelderMead_a43270e9ce4397f0eb70567b5e8b679db}{Nelder\+Mead}}, \mbox{\hyperlink{classNeuralMinimizer_afdda348f45b548b3aa642feaa515b38b}{Neural\+Minimizer}}, \mbox{\hyperlink{classSAOP_abd9bfc9989a7594315aa8ecf489d02ab}{SAOP}}, \mbox{\hyperlink{classSimanMethod_aeedf1ee020c36c3a2e579be35eb0de60}{Siman\+Method}}, and \mbox{\hyperlink{classWOA_a8fa73b41a14754efe048ea33cfbe6316}{WOA}}.

\mbox{\Hypertarget{classOptimizer_a2b3ee87deb4b5218adfece7ecaad5cb1}\label{classOptimizer_a2b3ee87deb4b5218adfece7ecaad5cb1}} 
\index{Optimizer@{Optimizer}!step@{step}}
\index{step@{step}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{step()}{step()}}
{\footnotesize\ttfamily void Optimizer\+::step (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



step, the step of the optimizer 



Reimplemented in \mbox{\hyperlink{classACOP_a3e398d65a6c64e07975e1aaa4b83ef9e}{ACOP}}, \mbox{\hyperlink{classAdam_a799f479790cd5b7718faa27da674ce0f}{Adam}}, \mbox{\hyperlink{classArmadillo1_a1ec8511bd606cfe59f82f4653816ae39}{Armadillo1}}, \mbox{\hyperlink{classBfgs_aabc4e600745446244fa7600bc0f6d5e5}{Bfgs}}, \mbox{\hyperlink{classDifferentialEvolution_ac28924d8657292a3294a127250afb272}{Differential\+Evolution}}, \mbox{\hyperlink{classEGO_a3ff3a66c9f46acf023b5aee3672a1673}{EGO}}, \mbox{\hyperlink{classGenetic_a5be34793c17531145f746703eb683400}{Genetic}}, \mbox{\hyperlink{classGradientDescent_a9b29de8013f85b9b04601b5bbaa610f2}{Gradient\+Descent}}, \mbox{\hyperlink{classGWOoptimizer_ac41739246cc4e70ee18897fb280bdfd0}{GWOoptimizer}}, \mbox{\hyperlink{classHybridMethod_ab117c06b21cefc7934292cf227fa938f}{Hybrid\+Method}}, \mbox{\hyperlink{classiPso_a18dd93cb75ff9dffea7ad8feab63bebb}{i\+Pso}}, \mbox{\hyperlink{classjDElsgo_a17c1d72feef8d5a1309f262f48e2b223}{j\+DElsgo}}, \mbox{\hyperlink{classLbfgs_afc102dbad8a7b845c064693879ba8b26}{Lbfgs}}, \mbox{\hyperlink{classMEWOA_a90c1ba46bd8ac4ad043b68d1f8eb20d8}{MEWOA}}, \mbox{\hyperlink{classMultistart_a7df293ab165c33d0861081380d60d12b}{Multistart}}, \mbox{\hyperlink{classNelderMead_a332faf407572224fb928722c11ff9160}{Nelder\+Mead}}, \mbox{\hyperlink{classNeuralMinimizer_a240e2af5d749de04da2d36e942865288}{Neural\+Minimizer}}, \mbox{\hyperlink{classOFAlgorithm_ab77a9b4cc90e9f28b421007a91d09aaa}{OFAlgorithm}}, \mbox{\hyperlink{classParallelDe_a2833cfcf3b9bb9285eba533e0bf4b8b3}{Parallel\+De}}, \mbox{\hyperlink{classParallelPso_a258a2b42cb2093df009af123f312b6ce}{Parallel\+Pso}}, \mbox{\hyperlink{classSAOP_a52bb9ced5158b416dc169aacf178d268}{SAOP}}, \mbox{\hyperlink{classSimanMethod_a04d91d5fccc37b0467759f2c2bd93cdf}{Siman\+Method}}, \mbox{\hyperlink{classUserMethod_aba68e99f946bf1a3d5a879cdfd42b071}{User\+Method}}, and \mbox{\hyperlink{classWOA_a69010f76238281643806f5bcd9da2600}{WOA}}.

\mbox{\Hypertarget{classOptimizer_a52c02dc16fbc45201ab64a1c542dea41}\label{classOptimizer_a52c02dc16fbc45201ab64a1c542dea41}} 
\index{Optimizer@{Optimizer}!terminated@{terminated}}
\index{terminated@{terminated}!Optimizer@{Optimizer}}
\doxysubsubsection{\texorpdfstring{terminated()}{terminated()}}
{\footnotesize\ttfamily bool Optimizer\+::terminated (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



terminated 

\begin{DoxyReturn}{Returns}
true if the method should terminate 
\end{DoxyReturn}


Reimplemented in \mbox{\hyperlink{classACOP_a411f35f41394272942f0dbb411ce306a}{ACOP}}, \mbox{\hyperlink{classAdam_ade1a729984dfa31866447d39baca29ee}{Adam}}, \mbox{\hyperlink{classArmadillo1_acbb54ac4eb23c37ea3425172152e7504}{Armadillo1}}, \mbox{\hyperlink{classBfgs_a5e99c4326ead425ba939657e0130cc5a}{Bfgs}}, \mbox{\hyperlink{classDifferentialEvolution_a1e6436b21c3fcfb8b94ff4578ebbcd0c}{Differential\+Evolution}}, \mbox{\hyperlink{classEGO_af2412eb175bf0651c829f3ab512624dc}{EGO}}, \mbox{\hyperlink{classGenetic_a6628eb5c0234bb185abd69955f2597f4}{Genetic}}, \mbox{\hyperlink{classGradientDescent_a3de64b31e29f2fefb2f7c772dd696826}{Gradient\+Descent}}, \mbox{\hyperlink{classGWOoptimizer_a01289acc4b1cad990833ec5d85313060}{GWOoptimizer}}, \mbox{\hyperlink{classHybridMethod_a136aa9ae50fd626af0ce6762e8a552fe}{Hybrid\+Method}}, \mbox{\hyperlink{classiPso_aec5d8cf19430526bdaf1cc66e3bcff5f}{i\+Pso}}, \mbox{\hyperlink{classjDElsgo_a72640647e303fc244f5d9b0dfb79a1ce}{j\+DElsgo}}, \mbox{\hyperlink{classLbfgs_ac8d218d65ff0a0958455ad505a5464cd}{Lbfgs}}, \mbox{\hyperlink{classMEWOA_a96db91f7ffe54375b41842c04aac8d8c}{MEWOA}}, \mbox{\hyperlink{classMultistart_ac9b99cd871bcfd320433ca8772383c65}{Multistart}}, \mbox{\hyperlink{classNelderMead_a4789fca19a2f657d71d53316579814e9}{Nelder\+Mead}}, \mbox{\hyperlink{classNeuralMinimizer_adef803b80231e4cf79883d526027ada1}{Neural\+Minimizer}}, \mbox{\hyperlink{classOFAlgorithm_ad5185e8dd2632275b8853bd1d2a9075e}{OFAlgorithm}}, \mbox{\hyperlink{classParallelDe_ab2f44822862cfffb5fcb0409e743cfe3}{Parallel\+De}}, \mbox{\hyperlink{classParallelPso_aaa55f1f9883667516efe4f8e5840b3f4}{Parallel\+Pso}}, \mbox{\hyperlink{classSAOP_ac92c0c1a20fb13f7f13b4b81c8b7c946}{SAOP}}, \mbox{\hyperlink{classSimanMethod_adb5a9ecc40d1f3f69365ef6fe2eecff6}{Siman\+Method}}, \mbox{\hyperlink{classUserMethod_a35736e96785c43d93e4c737c12bfe8d8}{User\+Method}}, and \mbox{\hyperlink{classWOA_a9e981fc0c88cf5edddc6d88c76d7121a}{WOA}}.

